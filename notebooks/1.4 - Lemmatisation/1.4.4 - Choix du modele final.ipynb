{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluation des résultats de lemmatisation \n",
    "==================================\n",
    "\n",
    "# Objectifs\n",
    "\n",
    "1. Lecture des logs\n",
    "2. Alignement avec types de modèles\n",
    "3. Lectures des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# IMPORTANT: THIS IS HARD CODED, SUPPORT FOR ALL LEMMA FROM DEV SET\n",
    "\n",
    "nb_words_dev_set = 19546\n",
    "\n",
    "\n",
    "models = [\n",
    "    \n",
    "]\n",
    "ModelScheme = {\n",
    "    \"config\": \"\",\n",
    "    \"tar\": \"\",\n",
    "}\n",
    "for file in glob.glob(\n",
    "    \"/home/thibault/dev/these/notebooks/1.4 - Lemmatisation/1.4.4 - Modele choice/*.log\"):\n",
    "    with open(file) as f:\n",
    "        config = None\n",
    "        current_task = None\n",
    "        current = {\n",
    "            \"scores\": {},\n",
    "            \"eval-time\": []\n",
    "        }\n",
    "        for line in f:\n",
    "            if line.startswith(\"config_path: \"):\n",
    "                current[\"config\"] = line.strip()[len(\"config_path: \"):]\n",
    "            elif \"Bye\" in line.strip():\n",
    "                models.append(current)\n",
    "                current = {\n",
    "                    \"scores\": {},\n",
    "                    \"eval-time\": []\n",
    "                }\n",
    "                current_task = None\n",
    "            elif line.startswith(\"#\"):\n",
    "                current_task = line.strip()[len(\"## \"):]\n",
    "                current[\"scores\"][current_task] = {}\n",
    "            elif current_task and line.startswith(\"|\"):  # We already have a task recorded\n",
    "                cat, acc, pre, rec, sup = [x.strip() for x in line.strip().split(\"|\") if x]\n",
    "                if sup == \"support\" or \"---\" in sup:\n",
    "                    continue\n",
    "                current[\"scores\"][current_task][cat] = (float(acc), float(pre), float(rec), int(sup))\n",
    "            elif \".tar\" in line:\n",
    "                current[\"file\"] = line.strip()[len(\"Saved best model to: [\"):-1]\n",
    "            elif \"Finished training in \" in line:\n",
    "                current[\"training-time\"] = float(line.strip()[len(\"2020-04-23 23:13:33,251 : Finished training in [\"):-1])\n",
    "            elif \"Starting epoch\" in line:\n",
    "                current[\"nb-epochs\"] = int(line.strip()[len(\"2020-04-23 20:23:00,051 : Starting epoch [\"):-1])\n",
    "            elif \"Evaluation time: \" in line:\n",
    "                current[\"eval-time\"].append(\n",
    "                    float(line.strip()[len(\"2020-04-24 04:04:56,425 : Evaluation time: \"):-len(\" sec\")])\n",
    "                )\n",
    "                \n",
    "models = {\n",
    "    model[\"file\"]: model for model in models\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = [\n",
    "    \"file\", \"conf\",\n",
    "    \n",
    "    \"acc\", \"acc-amb\", \"acc-unk-tar\", \"acc-unk-tok\",\n",
    "    \"pos\", \"pos-amb\", \n",
    "    \"gend\", \"gend-amb\", \n",
    "    \n",
    "    \"Unk-tar-support\", \"Unk-toks-support\", \"All support\",\n",
    "    \n",
    "    \"training-time\", \"nb-epochs\", \"Sec / Epoch\",\n",
    "    \n",
    "    \"Average Dev Test Time\",\n",
    "    \"sec / 1000 words\"\n",
    "]\n",
    "\n",
    "files = sorted(list(models.keys()))\n",
    "\n",
    "table = []\n",
    "for file in files:\n",
    "    table.append([\n",
    "        file,\n",
    "        models[file][\"config\"],\n",
    "        # Accuracies\n",
    "        models[file][\"scores\"][\"lemma\"][\"all\"][0],\n",
    "        models[file][\"scores\"][\"lemma\"][\"ambiguous-tokens\"][0],\n",
    "        models[file][\"scores\"][\"lemma\"][\"unknown-targets\"][0],\n",
    "        models[file][\"scores\"][\"lemma\"][\"unknown-tokens\"][0],\n",
    "        # POS\n",
    "        models[file][\"scores\"][\"pos\"][\"all\"][0],\n",
    "        models[file][\"scores\"][\"pos\"][\"ambiguous-tokens\"][0],\n",
    "        # POS\n",
    "        models[file][\"scores\"][\"Gend\"][\"all\"][0],\n",
    "        models[file][\"scores\"][\"Gend\"][\"ambiguous-tokens\"][0],\n",
    "        # Supports\n",
    "        models[file][\"scores\"][\"lemma\"][\"ambiguous-tokens\"][-1],\n",
    "        models[file][\"scores\"][\"lemma\"][\"unknown-tokens\"][-1],\n",
    "        models[file][\"scores\"][\"lemma\"][\"all\"][-1],\n",
    "        # Time\n",
    "        models[file].get(\"training-time\", 0),\n",
    "        models[file][\"nb-epochs\"],\n",
    "        round(models[file].get(\"training-time\", 0) / models[file][\"nb-epochs\"], 2),\n",
    "        # Inference time\n",
    "        round(sum(models[file][\"eval-time\"][1:]) / len(models[file][\"eval-time\"][1:]), 2),\n",
    "        round(\n",
    "            nb_words_dev_set /\n",
    "            (sum(models[file][\"eval-time\"][1:]) / len(models[file][\"eval-time\"][1:]))\n",
    "            , 2\n",
    "        )\n",
    "        \n",
    "    ])\n",
    "    \n",
    "table = sorted(table, key=lambda x: x[2])  # 2 is acc, 3 amb, 5 tokens\n",
    "table = [column] + table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>file                                             </td><td>conf                       </td><td>acc   </td><td>acc-amb</td><td>acc-unk-tar</td><td>acc-unk-tok</td><td>pos   </td><td>pos-amb</td><td>gend  </td><td>gend-amb</td><td>Unk-tar-support</td><td>Unk-toks-support</td><td>All support</td><td>training-time</td><td>nb-epochs</td><td>Sec / Epoch</td><td>Average Dev Test Time</td><td>sec / 1000 words</td></tr>\n",
       "<tr><td>./models/FinalModel-lemma-2020_05_05-15_17_40.tar</td><td>./configs/final_config.json</td><td>0.9721</td><td>0.9213 </td><td>0.6533     </td><td>0.864      </td><td>0.9647</td><td>0.9114 </td><td>0.9651</td><td>0.869   </td><td>41834          </td><td>6535            </td><td>169822     </td><td>18562.3      </td><td>69       </td><td>269.02     </td><td>7.94                 </td><td>2460.28         </td></tr>\n",
       "<tr><td>./models/FinalModel-lemma-2020_05_04-23_17_25.tar</td><td>./configs/final_config.json</td><td>0.9724</td><td>0.9226 </td><td>0.6351     </td><td>0.8637     </td><td>0.9651</td><td>0.9098 </td><td>0.9671</td><td>0.8725  </td><td>41834          </td><td>6535            </td><td>169822     </td><td>12698.2      </td><td>47       </td><td>270.17     </td><td>8.01                 </td><td>2440.38         </td></tr>\n",
       "<tr><td>./models/FinalModel-lemma-2020_05_04-19_44_27.tar</td><td>./configs/final_config.json</td><td>0.9739</td><td>0.9274 </td><td>0.4941     </td><td>0.856      </td><td>0.9656</td><td>0.9128 </td><td>0.9656</td><td>0.8701  </td><td>41834          </td><td>6535            </td><td>169822     </td><td>18890.9      </td><td>70       </td><td>269.87     </td><td>7.97                 </td><td>2451.0          </td></tr>\n",
       "<tr><td>./models/FinalModel-lemma-2020_05_05-10_06_59.tar</td><td>./configs/final_config.json</td><td>0.9748</td><td>0.9288 </td><td>0.6652     </td><td>0.8759     </td><td>0.9655</td><td>0.9128 </td><td>0.9659</td><td>0.8712  </td><td>41834          </td><td>6535            </td><td>169822     </td><td>19964.6      </td><td>74       </td><td>269.79     </td><td>7.98                 </td><td>2448.63         </td></tr>\n",
       "<tr><td>./models/FinalModel-lemma-2020_05_05-04_32_56.tar</td><td>./configs/final_config.json</td><td>0.9752</td><td>0.9295 </td><td>0.6597     </td><td>0.8771     </td><td>0.9667</td><td>0.915  </td><td>0.968 </td><td>0.8772  </td><td>41834          </td><td>6535            </td><td>169822     </td><td>18851.0      </td><td>70       </td><td>269.3      </td><td>7.98                 </td><td>2450.13         </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table like representation\n",
    "import tabulate\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping the best model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {\n",
    "    \n",
    "}\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Infos = namedtuple(\"Infos\", [\"tar\", \"acc\", \"amb\", \"tok\", \"train\", \"nbepoch\", \"sec_epoch\", \"sec_words\"])\n",
    "for tar, conf, acc, amb, _, tok, *_, train_time, nb_epochs, sec_epochs, _, words_sec in table[1:]:\n",
    "    if conf not in best:\n",
    "        best[conf] = Infos(tar, acc, amb, tok, train_time, nb_epochs, sec_epochs, words_sec)\n",
    "        continue\n",
    "    if best[conf].acc < acc:\n",
    "        best[conf] = Infos(tar, acc, amb, tok, train_time, nb_epochs, sec_epochs, words_sec)\n",
    "    \n",
    "column = [\n",
    "    \"file\", \"conf\",\n",
    "    \"acc-all\", \"acc-amb\", \"acc-unk-tok\",\n",
    "    \"training-time\", \"nb-epochs\", \"Sec / Epoch\",\n",
    "    \"sec / 1000 words\"\n",
    "]\n",
    "table2 = []\n",
    "for conf, values in best.items():\n",
    "    table2.append([conf, *values])\n",
    "    \n",
    "table2 = sorted(table2, key=lambda x: x[2])  # 2 is acc, 3 amb, 4 tokens\n",
    "table2 = [column] + table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>file                       </td><td>conf                                             </td><td>acc-all</td><td>acc-amb</td><td>acc-unk-tok</td><td>training-time</td><td>nb-epochs</td><td>Sec / Epoch</td><td>sec / 1000 words</td></tr>\n",
       "<tr><td>./configs/final_config.json</td><td>./models/FinalModel-lemma-2020_05_05-04_32_56.tar</td><td>0.9752 </td><td>0.9295 </td><td>0.8771     </td><td>18851.0      </td><td>70       </td><td>269.3      </td><td>2450.13         </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table like representation\n",
    "import tabulate\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(tabulate.tabulate(table2, tablefmt='html')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
