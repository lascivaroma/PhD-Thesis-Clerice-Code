{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluation des résultats de lemmatisation \n",
    "==================================\n",
    "\n",
    "# Objectifs\n",
    "\n",
    "1. Lecture des logs\n",
    "2. Alignement avec types de modèles\n",
    "3. Lectures des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# IMPORTANT: THIS IS HARD CODED, SUPPORT FOR ALL LEMMA FROM DEV SET\n",
    "\n",
    "nb_words_dev_set = 19546\n",
    "\n",
    "\n",
    "models = [\n",
    "    \n",
    "]\n",
    "ModelScheme = {\n",
    "    \"config\": \"\",\n",
    "    \"tar\": \"\",\n",
    "}\n",
    "for file in glob.glob(\n",
    "    \"/home/thibault/dev/these/notebooks/1.4 - Lemmatisation/1.4.4 \"\n",
    "    \"- Configuration de lemmatisation/Logs/*.log\"):\n",
    "    with open(file) as f:\n",
    "        config = None\n",
    "        current_task = None\n",
    "        current = {\n",
    "            \"scores\": {},\n",
    "            \"eval-time\": []\n",
    "        }\n",
    "        for line in f:\n",
    "            if line.startswith(\"config_path: \"):\n",
    "                current[\"config\"] = line.strip()[len(\"config_path: \"):]\n",
    "            elif \"Bye\" in line.strip():\n",
    "                models.append(current)\n",
    "                current = {\n",
    "                    \"scores\": {},\n",
    "                    \"eval-time\": []\n",
    "                }\n",
    "                current_task = None\n",
    "            elif line.startswith(\"#\"):\n",
    "                current_task = line.strip()[len(\"## \"):]\n",
    "                current[\"scores\"][current_task] = {}\n",
    "            elif current_task and line.startswith(\"|\"):  # We already have a task recorded\n",
    "                cat, acc, pre, rec, sup = [x.strip() for x in line.strip().split(\"|\") if x]\n",
    "                if sup == \"support\" or \"---\" in sup:\n",
    "                    continue\n",
    "                current[\"scores\"][current_task][cat] = (float(acc), float(pre), float(rec), int(sup))\n",
    "            elif \".tar\" in line:\n",
    "                current[\"file\"] = line.strip()[len(\"Saved best model to: [\"):-1]\n",
    "            elif \"Finished training in \" in line:\n",
    "                current[\"training-time\"] = float(line.strip()[len(\"2020-04-23 23:13:33,251 : Finished training in [\"):-1])\n",
    "            elif \"Starting epoch\" in line:\n",
    "                current[\"nb-epochs\"] = int(line.strip()[len(\"2020-04-23 20:23:00,051 : Starting epoch [\"):-1])\n",
    "            elif \"Evaluation time: \" in line:\n",
    "                current[\"eval-time\"].append(\n",
    "                    float(line.strip()[len(\"2020-04-24 04:04:56,425 : Evaluation time: \"):-len(\" sec\")])\n",
    "                )\n",
    "                \n",
    "models = {\n",
    "    model[\"file\"]: model for model in models\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = [\n",
    "    \"file\", \"conf\",\n",
    "    \n",
    "    \"acc\", \"acc-amb\", \"acc-unk-tar\", \"acc-unk-tok\",\n",
    "    \"pos\", \"pos-amb\", \n",
    "    \"gend\", \"gend-amb\", \n",
    "    \n",
    "    \"Unk-tar-support\", \"Unk-toks-support\", \"All support\",\n",
    "    \n",
    "    \"training-time\", \"nb-epochs\", \"Sec / Epoch\",\n",
    "    \n",
    "    \"Average Dev Test Time\",\n",
    "    \"sec / 1000 words\"\n",
    "]\n",
    "\n",
    "files = sorted(list(models.keys()))\n",
    "\n",
    "table = []\n",
    "for file in files:\n",
    "    table.append([\n",
    "        file,\n",
    "        models[file][\"config\"],\n",
    "        # Accuracies\n",
    "        models[file][\"scores\"][\"lemma\"][\"all\"][0],\n",
    "        models[file][\"scores\"][\"lemma\"][\"ambiguous-tokens\"][0],\n",
    "        models[file][\"scores\"][\"lemma\"][\"unknown-targets\"][0],\n",
    "        models[file][\"scores\"][\"lemma\"][\"unknown-tokens\"][0],\n",
    "        # POS\n",
    "        models[file][\"scores\"][\"pos\"][\"all\"][0],\n",
    "        models[file][\"scores\"][\"pos\"][\"ambiguous-tokens\"][0],\n",
    "        # POS\n",
    "        models[file][\"scores\"][\"Gend\"][\"all\"][0],\n",
    "        models[file][\"scores\"][\"Gend\"][\"ambiguous-tokens\"][0],\n",
    "        # Supports\n",
    "        models[file][\"scores\"][\"lemma\"][\"unknown-targets\"][-1],\n",
    "        models[file][\"scores\"][\"lemma\"][\"unknown-tokens\"][-1],\n",
    "        models[file][\"scores\"][\"lemma\"][\"all\"][-1],\n",
    "        # Time\n",
    "        models[file].get(\"training-time\", 0),\n",
    "        models[file][\"nb-epochs\"],\n",
    "        round(models[file].get(\"training-time\", 0) / models[file][\"nb-epochs\"], 2),\n",
    "        # Inference time\n",
    "        round(sum(models[file][\"eval-time\"][1:]) / len(models[file][\"eval-time\"][1:]), 2),\n",
    "        round(\n",
    "            nb_words_dev_set /\n",
    "            (sum(models[file][\"eval-time\"][1:]) / len(models[file][\"eval-time\"][1:]))\n",
    "            , 2\n",
    "        )\n",
    "        \n",
    "    ])\n",
    "    \n",
    "table = sorted(table, key=lambda x: x[2])  # 2 is acc, 3 amb, 5 tokens\n",
    "table = [column] + table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>file                                                                                                         </td><td>conf                                                                                             </td><td>acc   </td><td>acc-amb</td><td>acc-unk-tar</td><td>acc-unk-tok</td><td>pos   </td><td>pos-amb</td><td>gend  </td><td>gend-amb</td><td>Unk-tar-support</td><td>Unk-toks-support</td><td>All support</td><td>training-time</td><td>nb-epochs</td><td>Sec / Epoch</td><td>Average Dev Test Time</td><td>sec / 1000 words</td></tr>\n",
       "<tr><td>./models/cemb_CNN_-wemb_none_-lrpatience_4;7_-lemma-2020_04_24-00_37_47.tar                                  </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-nowemb.json                                                     </td><td>0.9555</td><td>0.8957 </td><td>0.5019     </td><td>0.7739     </td><td>0.8972</td><td>0.8385 </td><td>0.9163</td><td>0.7524  </td><td>771            </td><td>5773            </td><td>172968     </td><td>4929.73      </td><td>27       </td><td>182.58     </td><td>7.12                 </td><td>2744.64         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_-wemb_none_-lrpatience_4;7_-lemma-2020_04_24-11_24_15.tar                                  </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-nowemb.json                                                     </td><td>0.9601</td><td>0.8995 </td><td>0.5201     </td><td>0.8032     </td><td>0.9234</td><td>0.8667 </td><td>0.9286</td><td>0.7852  </td><td>771            </td><td>5773            </td><td>172968     </td><td>9192.01      </td><td>50       </td><td>183.84     </td><td>7.12                 </td><td>2746.92         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_-wemb_none_-lrpatience_4;7_-lemma-2020_04_24-23_42_23.tar                                  </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-nowemb.json                                                     </td><td>0.9611</td><td>0.9026 </td><td>0.5292     </td><td>0.8003     </td><td>0.9274</td><td>0.8704 </td><td>0.9267</td><td>0.7911  </td><td>771            </td><td>5773            </td><td>172968     </td><td>8025.91      </td><td>44       </td><td>182.41     </td><td>7.12                 </td><td>2743.74         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_5;7_-lemma-2020_04_24-05_39_38.tar                                  </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-nowemb.json                                                     </td><td>0.9619</td><td>0.8997 </td><td>0.5837     </td><td>0.8157     </td><td>0.9582</td><td>0.894  </td><td>0.9589</td><td>0.845   </td><td>771            </td><td>5773            </td><td>172968     </td><td>5071.46      </td><td>22       </td><td>230.52     </td><td>7.73                 </td><td>2528.08         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_-patience_5_-lemma-2020_04_23-00_52_52.tar                                                 </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-patience.json                                                   </td><td>0.9627</td><td>0.9102 </td><td>0.5629     </td><td>0.8027     </td><td>0.9511</td><td>0.8989 </td><td>0.951 </td><td>0.8425  </td><td>771            </td><td>5773            </td><td>172968     </td><td>7357.5       </td><td>38       </td><td>193.62     </td><td>7.2                  </td><td>2713.18         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_-patience_5_-lemma-2020_04_23-04_14_02.tar                                                 </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-patience.json                                                   </td><td>0.9642</td><td>0.912  </td><td>0.5162     </td><td>0.8025     </td><td>0.9496</td><td>0.8959 </td><td>0.9494</td><td>0.8354  </td><td>771            </td><td>5773            </td><td>172968     </td><td>5945.53      </td><td>31       </td><td>191.79     </td><td>7.15                 </td><td>2732.68         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_5;7_-lemma-2020_04_24-17_11_30.tar                                  </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-nowemb.json                                                     </td><td>0.9644</td><td>0.9049 </td><td>0.5824     </td><td>0.8186     </td><td>0.9595</td><td>0.8967 </td><td>0.9616</td><td>0.8545  </td><td>771            </td><td>5773            </td><td>172968     </td><td>7970.75      </td><td>34       </td><td>234.43     </td><td>7.96                 </td><td>2454.68         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_-patience_5_-lemma-2020_04_23-08_27_33.tar                                                 </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-patience.json                                                   </td><td>0.9648</td><td>0.9127 </td><td>0.5279     </td><td>0.8096     </td><td>0.9499</td><td>0.898  </td><td>0.9515</td><td>0.8432  </td><td>771            </td><td>5773            </td><td>172968     </td><td>7871.38      </td><td>41       </td><td>191.98     </td><td>7.18                 </td><td>2722.2          </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-patience_5_-lemma-2020_04_23-02_33_41.tar                                                 </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-patience.json                                                   </td><td>0.9656</td><td>0.9089 </td><td>0.5863     </td><td>0.823      </td><td>0.958 </td><td>0.897  </td><td>0.9608</td><td>0.8555  </td><td>771            </td><td>5773            </td><td>172968     </td><td>5970.14      </td><td>25       </td><td>238.81     </td><td>7.74                 </td><td>2526.48         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_--lemma-2020_04_22-16_14_40.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN.json                                                            </td><td>0.9662</td><td>0.9088 </td><td>0.4488     </td><td>0.8166     </td><td>0.9587</td><td>0.8982 </td><td>0.9604</td><td>0.8539  </td><td>771            </td><td>5773            </td><td>172968     </td><td>8149.98      </td><td>34       </td><td>239.71     </td><td>7.73                 </td><td>2528.34         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_--lemma-2020_04_21-21_17_56.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN.json                                                            </td><td>0.9668</td><td>0.9137 </td><td>0.62       </td><td>0.838      </td><td>0.9596</td><td>0.9024 </td><td>0.961 </td><td>0.8565  </td><td>771            </td><td>5773            </td><td>172968     </td><td>0            </td><td>29       </td><td>0.0        </td><td>7.78                 </td><td>2511.91         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_--lemma-2020_04_22-13_57_31.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN.json                                                            </td><td>0.9669</td><td>0.9123 </td><td>0.4578     </td><td>0.8212     </td><td>0.9624</td><td>0.9061 </td><td>0.9628</td><td>0.8606  </td><td>771            </td><td>5773            </td><td>172968     </td><td>10023.5      </td><td>42       </td><td>238.65     </td><td>7.73                 </td><td>2529.38         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_--lemma-2020_04_22-05_48_24.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN.json                                                            </td><td>0.9676</td><td>0.9124 </td><td>0.5914     </td><td>0.8394     </td><td>0.9591</td><td>0.9005 </td><td>0.9605</td><td>0.8568  </td><td>771            </td><td>5773            </td><td>172968     </td><td>9783.8       </td><td>41       </td><td>238.63     </td><td>7.74                 </td><td>2525.84         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-patience_5_-lemma-2020_04_23-10_32_22.tar                                                 </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-patience.json                                                   </td><td>0.9677</td><td>0.9137 </td><td>0.6278     </td><td>0.8398     </td><td>0.9583</td><td>0.899  </td><td>0.9604</td><td>0.8556  </td><td>771            </td><td>5773            </td><td>172968     </td><td>7411.9       </td><td>31       </td><td>239.09     </td><td>7.63                 </td><td>2560.85         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-patience_5_-lemma-2020_04_23-06_15_06.tar                                                 </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-patience.json                                                   </td><td>0.9681</td><td>0.9124 </td><td>0.5953     </td><td>0.837      </td><td>0.9575</td><td>0.8953 </td><td>0.9598</td><td>0.8529  </td><td>771            </td><td>5773            </td><td>172968     </td><td>7185.86      </td><td>30       </td><td>239.53     </td><td>7.69                 </td><td>2543.36         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_5;7_-lemma-2020_04_25-05_48_34.tar                                  </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-nowemb.json                                                     </td><td>0.9686</td><td>0.9126 </td><td>0.5888     </td><td>0.836      </td><td>0.9611</td><td>0.9001 </td><td>0.9613</td><td>0.8512  </td><td>771            </td><td>5773            </td><td>172968     </td><td>9665.27      </td><td>42       </td><td>230.13     </td><td>7.68                 </td><td>2546.52         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_--lemma-2020_04_22-00_14_57.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN.json                                                            </td><td>0.9688</td><td>0.914  </td><td>0.6005     </td><td>0.8439     </td><td>0.9596</td><td>0.8998 </td><td>0.9623</td><td>0.8589  </td><td>771            </td><td>5773            </td><td>172968     </td><td>10541.5      </td><td>44       </td><td>239.58     </td><td>7.77                 </td><td>2517.12         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_--lemma-2020_04_22-08_36_17.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN.json                                                            </td><td>0.9688</td><td>0.9151 </td><td>0.6122     </td><td>0.8457     </td><td>0.9619</td><td>0.9047 </td><td>0.9636</td><td>0.8649  </td><td>771            </td><td>5773            </td><td>172968     </td><td>9995.51      </td><td>42       </td><td>237.99     </td><td>7.66                 </td><td>2553.36         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_--lemma-2020_04_22-19_07_19.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN.json                                                            </td><td>0.9698</td><td>0.9167 </td><td>0.4825     </td><td>0.8318     </td><td>0.9612</td><td>0.9014 </td><td>0.9632</td><td>0.8618  </td><td>771            </td><td>5773            </td><td>172968     </td><td>10278.1      </td><td>42       </td><td>244.72     </td><td>8.01                 </td><td>2439.84         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_--lemma-2020_04_22-11_09_09.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN.json                                                            </td><td>0.97  </td><td>0.916  </td><td>0.4812     </td><td>0.8382     </td><td>0.9608</td><td>0.9005 </td><td>0.9644</td><td>0.866   </td><td>771            </td><td>5773            </td><td>172968     </td><td>9093.52      </td><td>38       </td><td>239.3      </td><td>7.7                  </td><td>2538.53         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_--lemma-2020_04_22-03_04_02.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN.json                                                            </td><td>0.9707</td><td>0.9177 </td><td>0.6135     </td><td>0.8562     </td><td>0.9625</td><td>0.9034 </td><td>0.9647</td><td>0.8662  </td><td>771            </td><td>5773            </td><td>172968     </td><td>10065.2      </td><td>42       </td><td>239.65     </td><td>7.77                 </td><td>2515.72         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_--lemma-2020_04_22-22_48_00.tar                                                            </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN.json                                                            </td><td>0.9707</td><td>0.9171 </td><td>0.6057     </td><td>0.85       </td><td>0.9611</td><td>0.8998 </td><td>0.9597</td><td>0.8484  </td><td>771            </td><td>5773            </td><td>172968     </td><td>0            </td><td>56       </td><td>0.0        </td><td>7.71                 </td><td>2534.17         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_-lrpatience_4;7_-lemma-2020_04_24-08_49_48.tar                                             </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-lrpatience.json                                                 </td><td>0.9718</td><td>0.9239 </td><td>0.5772     </td><td>0.8451     </td><td>0.9545</td><td>0.9049 </td><td>0.9571</td><td>0.8573  </td><td>771            </td><td>5773            </td><td>172968     </td><td>11333.5      </td><td>59       </td><td>192.09     </td><td>7.17                 </td><td>2724.4          </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-lemma-2020_04_27-14_59_01.tar                       </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256.json                                     </td><td>0.9726</td><td>0.9226 </td><td>0.4254     </td><td>0.8401     </td><td>0.9633</td><td>0.9057 </td><td>0.9641</td><td>0.8634  </td><td>771            </td><td>5773            </td><td>172968     </td><td>11995.4      </td><td>50       </td><td>239.91     </td><td>7.79                 </td><td>2508.28         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400-lemma-2020_04_30-00_29_59.tar     </td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400.json     </td><td>0.9727</td><td>0.9208 </td><td>0.5824     </td><td>0.8581     </td><td>0.9653</td><td>0.9091 </td><td>0.9666</td><td>0.8707  </td><td>771            </td><td>5773            </td><td>172968     </td><td>14182.8      </td><td>50       </td><td>283.66     </td><td>8.16                 </td><td>2396.49         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2-lemma-2020_04_26-23_08_20.tar              </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-layers_2.json                            </td><td>0.9728</td><td>0.9217 </td><td>0.5927     </td><td>0.8599     </td><td>0.9649</td><td>0.9115 </td><td>0.9695</td><td>0.8861  </td><td>771            </td><td>5773            </td><td>172968     </td><td>12984.1      </td><td>53       </td><td>244.98     </td><td>7.83                 </td><td>2495.83         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-lemma-2020_04_26-19_30_36.tar                       </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256.json                                     </td><td>0.9734</td><td>0.9239 </td><td>0.4929     </td><td>0.8469     </td><td>0.9649</td><td>0.9099 </td><td>0.9652</td><td>0.8678  </td><td>771            </td><td>5773            </td><td>172968     </td><td>15420.7      </td><td>64       </td><td>240.95     </td><td>7.82                 </td><td>2500.2          </td></tr>\n",
       "<tr><td>./models/cemb_CNN_-lrpatience_4;7_-lemma-2020_04_24-21_27_22.tar                                             </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-lrpatience.json                                                 </td><td>0.9735</td><td>0.9263 </td><td>0.5447     </td><td>0.8536     </td><td>0.9524</td><td>0.9012 </td><td>0.9554</td><td>0.854   </td><td>771            </td><td>5773            </td><td>172968     </td><td>15276.1      </td><td>80       </td><td>190.95     </td><td>7.16                 </td><td>2730.62         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500-lemma-2020_04_29-05_59_21.tar     </td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500.json     </td><td>0.9735</td><td>0.9245 </td><td>0.5305     </td><td>0.8483     </td><td>0.9656</td><td>0.9106 </td><td>0.9653</td><td>0.866   </td><td>771            </td><td>5773            </td><td>172968     </td><td>15325.7      </td><td>48       </td><td>319.29     </td><td>8.73                 </td><td>2239.58         </td></tr>\n",
       "<tr><td>./models/cemb_CNN_-lrpatience_4;7_-lemma-2020_04_23-23_14_22.tar                                             </td><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-lrpatience.json                                                 </td><td>0.9736</td><td>0.9272 </td><td>0.5642     </td><td>0.8526     </td><td>0.9543</td><td>0.9059 </td><td>0.9577</td><td>0.8623  </td><td>771            </td><td>5773            </td><td>172968     </td><td>13700.8      </td><td>72       </td><td>190.29     </td><td>7.15                 </td><td>2733.38         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_200_min_5_-lrpatience_4_7_-hidden-256-lemma-2020_04_27-02_14_31.tar                  </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb_200-hidden_256.json                                   </td><td>0.9736</td><td>0.9258 </td><td>0.6018     </td><td>0.8588     </td><td>0.9643</td><td>0.9102 </td><td>0.9644</td><td>0.8667  </td><td>771            </td><td>5773            </td><td>172968     </td><td>11091.6      </td><td>46       </td><td>241.12     </td><td>7.81                 </td><td>2501.2          </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400-lemma-2020_04_30-10_36_21.tar</td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400.json</td><td>0.9737</td><td>0.9227 </td><td>0.5992     </td><td>0.8587     </td><td>0.9671</td><td>0.9145 </td><td>0.9706</td><td>0.8874  </td><td>771            </td><td>5773            </td><td>172968     </td><td>16006.1      </td><td>55       </td><td>291.02     </td><td>8.19                 </td><td>2388.0          </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_200_min_5_-lrpatience_4_7_-hidden-256-lemma-2020_04_26-04_36_19.tar                  </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb_200-hidden_256.json                                   </td><td>0.9738</td><td>0.9269 </td><td>0.6005     </td><td>0.8576     </td><td>0.9641</td><td>0.9098 </td><td>0.9655</td><td>0.8711  </td><td>771            </td><td>5773            </td><td>172968     </td><td>9408.84      </td><td>39       </td><td>241.25     </td><td>7.79                 </td><td>2510.02         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400-lemma-2020_04_29-10_36_19.tar</td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400.json</td><td>0.9741</td><td>0.9242 </td><td>0.5914     </td><td>0.8626     </td><td>0.9678</td><td>0.9166 </td><td>0.9708</td><td>0.887   </td><td>771            </td><td>5773            </td><td>172968     </td><td>16536.6      </td><td>57       </td><td>290.12     </td><td>8.15                 </td><td>2398.44         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_100_min_5-lrpatience_4_7_-hidden-256-lemma-2020_04_28-04_13_20.tar                   </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb-hidden_256.json                                       </td><td>0.9748</td><td>0.9284 </td><td>0.6096     </td><td>0.8637     </td><td>0.9644</td><td>0.9102 </td><td>0.9663</td><td>0.8732  </td><td>771            </td><td>5773            </td><td>172968     </td><td>12255.7      </td><td>51       </td><td>240.31     </td><td>7.77                 </td><td>2514.09         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2-lemma-2020_04_26-01_58_10.tar              </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-layers_2.json                            </td><td>0.9749</td><td>0.9255 </td><td>0.5629     </td><td>0.869      </td><td>0.9677</td><td>0.9182 </td><td>0.9703</td><td>0.8887  </td><td>771            </td><td>5773            </td><td>172968     </td><td>16505.3      </td><td>66       </td><td>250.08     </td><td>8.05                 </td><td>2428.63         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-lrpatience_5;7_-lemma-2020_04_25-03_06_10.tar                                             </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-lrpatience.json                                                 </td><td>0.975 </td><td>0.9261 </td><td>0.6083     </td><td>0.8742     </td><td>0.9659</td><td>0.91   </td><td>0.9659</td><td>0.8686  </td><td>771            </td><td>5773            </td><td>172968     </td><td>12148.3      </td><td>51       </td><td>238.2      </td><td>7.71                 </td><td>2535.59         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_200_min_5_-lrpatience_4_7_-hidden-256-lemma-2020_04_28-00_47_44.tar                  </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb_200-hidden_256.json                                   </td><td>0.975 </td><td>0.9272 </td><td>0.6057     </td><td>0.8704     </td><td>0.9656</td><td>0.9117 </td><td>0.9645</td><td>0.8673  </td><td>771            </td><td>5773            </td><td>172968     </td><td>14947.7      </td><td>61       </td><td>245.04     </td><td>8.03                 </td><td>2434.53         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400-lemma-2020_04_29-01_42_32.tar     </td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400.json     </td><td>0.975 </td><td>0.9275 </td><td>0.6161     </td><td>0.8647     </td><td>0.9668</td><td>0.9124 </td><td>0.9671</td><td>0.8712  </td><td>771            </td><td>5773            </td><td>172968     </td><td>16204.4      </td><td>57       </td><td>284.29     </td><td>8.13                 </td><td>2402.77         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500-lemma-2020_05_01-10_30_32.tar     </td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500.json     </td><td>0.975 </td><td>0.9267 </td><td>0.6005     </td><td>0.8626     </td><td>0.9666</td><td>0.9129 </td><td>0.9666</td><td>0.8701  </td><td>771            </td><td>5773            </td><td>172968     </td><td>16206.6      </td><td>50       </td><td>324.13     </td><td>8.94                 </td><td>2185.97         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400-lemma-2020_04_29-20_32_14.tar</td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400.json</td><td>0.9751</td><td>0.9272 </td><td>0.4488     </td><td>0.8531     </td><td>0.9669</td><td>0.9149 </td><td>0.9706</td><td>0.8877  </td><td>771            </td><td>5773            </td><td>172968     </td><td>18806.1      </td><td>68       </td><td>276.56     </td><td>8.05                 </td><td>2427.74         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-lrpatience_5;7_-lemma-2020_04_24-04_13_47.tar                                             </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-lrpatience.json                                                 </td><td>0.9752</td><td>0.9262 </td><td>0.6083     </td><td>0.876      </td><td>0.9637</td><td>0.9081 </td><td>0.9657</td><td>0.8727  </td><td>771            </td><td>5773            </td><td>172968     </td><td>12882.4      </td><td>54       </td><td>238.56     </td><td>7.66                 </td><td>2552.38         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-lrpatience_5;7_-lemma-2020_04_24-14_57_20.tar                                             </td><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-lrpatience.json                                                 </td><td>0.9753</td><td>0.9267 </td><td>0.6291     </td><td>0.8779     </td><td>0.9662</td><td>0.9113 </td><td>0.9663</td><td>0.8697  </td><td>771            </td><td>5773            </td><td>172968     </td><td>12706.0      </td><td>53       </td><td>239.74     </td><td>7.64                 </td><td>2557.19         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500-lemma-2020_04_30-06_08_12.tar     </td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500.json     </td><td>0.9753</td><td>0.926  </td><td>0.5992     </td><td>0.8729     </td><td>0.9667</td><td>0.9132 </td><td>0.9648</td><td>0.8634  </td><td>771            </td><td>5773            </td><td>172968     </td><td>20209.6      </td><td>63       </td><td>320.79     </td><td>8.76                 </td><td>2230.5          </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400-lemma-2020_05_01-16_15_15.tar</td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400.json</td><td>0.9753</td><td>0.9261 </td><td>0.5888     </td><td>0.8684     </td><td>0.9681</td><td>0.918  </td><td>0.9714</td><td>0.8917  </td><td>771            </td><td>5773            </td><td>172968     </td><td>20601.8      </td><td>71       </td><td>290.17     </td><td>8.15                 </td><td>2398.39         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500-lemma-2020_04_28-14_20_03.tar     </td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500.json     </td><td>0.9754</td><td>0.9269 </td><td>0.594      </td><td>0.8689     </td><td>0.967 </td><td>0.9127 </td><td>0.9667</td><td>0.8689  </td><td>771            </td><td>5773            </td><td>172968     </td><td>19199.4      </td><td>62       </td><td>309.67     </td><td>8.8                  </td><td>2220.29         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400-lemma-2020_05_01-05_59_00.tar     </td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400.json     </td><td>0.9754</td><td>0.9278 </td><td>0.6031     </td><td>0.8697     </td><td>0.9645</td><td>0.9094 </td><td>0.9633</td><td>0.8607  </td><td>771            </td><td>5773            </td><td>172968     </td><td>19524.4      </td><td>69       </td><td>282.96     </td><td>8.08                 </td><td>2419.6          </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500-lemma-2020_04_30-17_05_16.tar     </td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500.json     </td><td>0.9755</td><td>0.9267 </td><td>0.5746     </td><td>0.8687     </td><td>0.9677</td><td>0.9142 </td><td>0.9679</td><td>0.8746  </td><td>771            </td><td>5773            </td><td>172968     </td><td>23251.9      </td><td>76       </td><td>305.95     </td><td>8.61                 </td><td>2269.13         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_100_min_5-lrpatience_4_7_-hidden-256-lemma-2020_04_27-06_24_27.tar                   </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb-hidden_256.json                                       </td><td>0.9756</td><td>0.9291 </td><td>0.607      </td><td>0.8735     </td><td>0.9639</td><td>0.9109 </td><td>0.9644</td><td>0.8703  </td><td>771            </td><td>5773            </td><td>172968     </td><td>14916.4      </td><td>62       </td><td>240.59     </td><td>7.76                 </td><td>2520.08         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-lemma-2020_04_25-21_21_44.tar                       </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256.json                                     </td><td>0.9759</td><td>0.9298 </td><td>0.5811     </td><td>0.8664     </td><td>0.9666</td><td>0.9132 </td><td>0.9673</td><td>0.8741  </td><td>771            </td><td>5773            </td><td>172968     </td><td>22034.4      </td><td>92       </td><td>239.5      </td><td>7.63                 </td><td>2561.09         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400-lemma-2020_04_28-21_11_06.tar</td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400.json</td><td>0.9761</td><td>0.9279 </td><td>0.5966     </td><td>0.8768     </td><td>0.9691</td><td>0.9217 </td><td>0.9712</td><td>0.8915  </td><td>771            </td><td>5773            </td><td>172968     </td><td>24581.9      </td><td>89       </td><td>276.2      </td><td>8.07                 </td><td>2422.34         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_100_min_5-lrpatience_4_7_-hidden-256-lemma-2020_04_26-08_46_04.tar                   </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb-hidden_256.json                                       </td><td>0.9762</td><td>0.9312 </td><td>0.6148     </td><td>0.877      </td><td>0.9666</td><td>0.9157 </td><td>0.9669</td><td>0.8769  </td><td>771            </td><td>5773            </td><td>172968     </td><td>14906.7      </td><td>62       </td><td>240.43     </td><td>7.61                 </td><td>2566.94         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500-lemma-2020_04_29-15_17_28.tar     </td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500.json     </td><td>0.9764</td><td>0.9298 </td><td>0.5979     </td><td>0.8716     </td><td>0.9672</td><td>0.9129 </td><td>0.9683</td><td>0.8757  </td><td>771            </td><td>5773            </td><td>172968     </td><td>16785.3      </td><td>55       </td><td>305.19     </td><td>8.56                 </td><td>2283.97         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2-lemma-2020_04_26-15_12_13.tar              </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-cemb_400.json                            </td><td>0.9764</td><td>0.929  </td><td>0.6005     </td><td>0.8784     </td><td>0.9665</td><td>0.9125 </td><td>0.9661</td><td>0.8691  </td><td>771            </td><td>5773            </td><td>172968     </td><td>23089.4      </td><td>85       </td><td>271.64     </td><td>8.07                 </td><td>2423.44         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2-lemma-2020_04_27-20_37_16.tar              </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-layers_2.json                            </td><td>0.9765</td><td>0.9307 </td><td>0.5837     </td><td>0.8734     </td><td>0.9702</td><td>0.9222 </td><td>0.9738</td><td>0.8985  </td><td>771            </td><td>5773            </td><td>172968     </td><td>20217.1      </td><td>83       </td><td>243.58     </td><td>7.74                 </td><td>2524.53         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2-lemma-2020_04_25-15_13_12.tar              </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-cemb_400.json                            </td><td>0.9766</td><td>0.9305 </td><td>0.6031     </td><td>0.8727     </td><td>0.967 </td><td>0.9138 </td><td>0.9678</td><td>0.8756  </td><td>771            </td><td>5773            </td><td>172968     </td><td>20874.2      </td><td>77       </td><td>271.09     </td><td>8.02                 </td><td>2435.98         </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2-lemma-2020_04_27-11_37_46.tar              </td><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-cemb_400.json                            </td><td>0.9767</td><td>0.9315 </td><td>0.6278     </td><td>0.8761     </td><td>0.9669</td><td>0.9131 </td><td>0.9677</td><td>0.8743  </td><td>771            </td><td>5773            </td><td>172968     </td><td>18718.3      </td><td>69       </td><td>271.28     </td><td>8.04                 </td><td>2432.4          </td></tr>\n",
       "<tr><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400-lemma-2020_05_01-00_32_16.tar</td><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400.json</td><td>0.9771</td><td>0.9318 </td><td>0.5811     </td><td>0.8781     </td><td>0.97  </td><td>0.9231 </td><td>0.9726</td><td>0.8959  </td><td>771            </td><td>5773            </td><td>172968     </td><td>26738.0      </td><td>97       </td><td>275.65     </td><td>8.08                 </td><td>2419.31         </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table like representation\n",
    "import tabulate\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(tabulate.tabulate(table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/1.4.4/results.csv\", \"w\") as f:\n",
    "    import csv\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping the best model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {\n",
    "    \n",
    "}\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Infos = namedtuple(\"Infos\", [\"tar\", \"acc\", \"amb\", \"tok\", \"train\", \"nbepoch\", \"sec_epoch\", \"sec_words\"])\n",
    "for tar, conf, acc, amb, _, tok, *_, train_time, nb_epochs, sec_epochs, _, words_sec in table[1:]:\n",
    "    if conf not in best:\n",
    "        best[conf] = Infos(tar, acc, amb, tok, train_time, nb_epochs, sec_epochs, words_sec)\n",
    "        continue\n",
    "    if best[conf].acc < acc:\n",
    "        best[conf] = Infos(tar, acc, amb, tok, train_time, nb_epochs, sec_epochs, words_sec)\n",
    "    \n",
    "column = [\n",
    "    \"file\", \"conf\",\n",
    "    \"acc-all\", \"acc-amb\", \"acc-unk-tok\",\n",
    "    \"training-time\", \"nb-epochs\", \"Sec / Epoch\",\n",
    "    \"sec / 1000 words\"\n",
    "]\n",
    "table2 = []\n",
    "for conf, values in best.items():\n",
    "    table2.append([conf, *values])\n",
    "    \n",
    "table2 = sorted(table2, key=lambda x: x[2])  # 2 is acc, 3 amb, 4 tokens\n",
    "table2 = [column] + table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>file                                                                                             </td><td>conf                                                                                                         </td><td>acc-all</td><td>acc-amb</td><td>acc-unk-tok</td><td>training-time</td><td>nb-epochs</td><td>Sec / Epoch</td><td>sec / 1000 words</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-nowemb.json                                                     </td><td>./models/cemb_CNN_-wemb_none_-lrpatience_4;7_-lemma-2020_04_24-23_42_23.tar                                  </td><td>0.9611 </td><td>0.9026 </td><td>0.8003     </td><td>8025.91      </td><td>44       </td><td>182.41     </td><td>2743.74         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-patience.json                                                   </td><td>./models/cemb_CNN_-patience_5_-lemma-2020_04_23-08_27_33.tar                                                 </td><td>0.9648 </td><td>0.9127 </td><td>0.8096     </td><td>7871.38      </td><td>41       </td><td>191.98     </td><td>2722.2          </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-patience.json                                                   </td><td>./models/cemb_RNN_-patience_5_-lemma-2020_04_23-06_15_06.tar                                                 </td><td>0.9681 </td><td>0.9124 </td><td>0.837      </td><td>7185.86      </td><td>30       </td><td>239.53     </td><td>2543.36         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-nowemb.json                                                     </td><td>./models/cemb_RNN_-wemb_none_-lrpatience_5;7_-lemma-2020_04_25-05_48_34.tar                                  </td><td>0.9686 </td><td>0.9126 </td><td>0.836      </td><td>9665.27      </td><td>42       </td><td>230.13     </td><td>2546.52         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-RNN.json                                                            </td><td>./models/cemb_RNN_--lemma-2020_04_22-22_48_00.tar                                                            </td><td>0.9707 </td><td>0.9171 </td><td>0.85       </td><td>0            </td><td>56       </td><td>0.0        </td><td>2534.17         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-CNN.json                                                            </td><td>./models/cemb_CNN_--lemma-2020_04_22-03_04_02.tar                                                            </td><td>0.9707 </td><td>0.9177 </td><td>0.8562     </td><td>10065.2      </td><td>42       </td><td>239.65     </td><td>2515.72         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-lrpatience.json                                                 </td><td>./models/cemb_CNN_-lrpatience_4;7_-lemma-2020_04_23-23_14_22.tar                                             </td><td>0.9736 </td><td>0.9272 </td><td>0.8526     </td><td>13700.8      </td><td>72       </td><td>190.29     </td><td>2733.38         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb_200-hidden_256.json                                   </td><td>./models/cemb_RNN_-wemb_200_min_5_-lrpatience_4_7_-hidden-256-lemma-2020_04_28-00_47_44.tar                  </td><td>0.975  </td><td>0.9272 </td><td>0.8704     </td><td>14947.7      </td><td>61       </td><td>245.04     </td><td>2434.53         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500.json     </td><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500-lemma-2020_04_30-06_08_12.tar     </td><td>0.9753 </td><td>0.926  </td><td>0.8729     </td><td>20209.6      </td><td>63       </td><td>320.79     </td><td>2230.5          </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400.json</td><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400-lemma-2020_05_01-16_15_15.tar</td><td>0.9753 </td><td>0.9261 </td><td>0.8684     </td><td>20601.8      </td><td>71       </td><td>290.17     </td><td>2398.39         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-lrpatience.json                                                 </td><td>./models/cemb_RNN_-lrpatience_5;7_-lemma-2020_04_24-14_57_20.tar                                             </td><td>0.9753 </td><td>0.9267 </td><td>0.8779     </td><td>12706.0      </td><td>53       </td><td>239.74     </td><td>2557.19         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400.json     </td><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400-lemma-2020_05_01-05_59_00.tar     </td><td>0.9754 </td><td>0.9278 </td><td>0.8697     </td><td>19524.4      </td><td>69       </td><td>282.96     </td><td>2419.6          </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256.json                                     </td><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-lemma-2020_04_25-21_21_44.tar                       </td><td>0.9759 </td><td>0.9298 </td><td>0.8664     </td><td>22034.4      </td><td>92       </td><td>239.5      </td><td>2561.09         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb-hidden_256.json                                       </td><td>./models/cemb_RNN_-wemb_100_min_5-lrpatience_4_7_-hidden-256-lemma-2020_04_26-08_46_04.tar                   </td><td>0.9762 </td><td>0.9312 </td><td>0.877      </td><td>14906.7      </td><td>62       </td><td>240.43     </td><td>2566.94         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500.json     </td><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500-lemma-2020_04_29-15_17_28.tar     </td><td>0.9764 </td><td>0.9298 </td><td>0.8716     </td><td>16785.3      </td><td>55       </td><td>305.19     </td><td>2283.97         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-layers_2.json                            </td><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2-lemma-2020_04_27-20_37_16.tar              </td><td>0.9765 </td><td>0.9307 </td><td>0.8734     </td><td>20217.1      </td><td>83       </td><td>243.58     </td><td>2524.53         </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-cemb_400.json                            </td><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2-lemma-2020_04_27-11_37_46.tar              </td><td>0.9767 </td><td>0.9315 </td><td>0.8761     </td><td>18718.3      </td><td>69       </td><td>271.28     </td><td>2432.4          </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400.json</td><td>./models/cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400-lemma-2020_05_01-00_32_16.tar</td><td>0.9771 </td><td>0.9318 </td><td>0.8781     </td><td>26738.0      </td><td>97       </td><td>275.65     </td><td>2419.31         </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table like representation\n",
    "import tabulate\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(tabulate.tabulate(table2, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>config_path                                                                                      </td><td>word_max_size</td><td>word_min_freq</td><td>patience</td><td>lr_patience</td><td>hidden_size</td><td>num_layers</td><td>wemb_dim</td><td>cemb_dim</td><td>cemb_type</td><td>score </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-nowemb.json                                                     </td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>128        </td><td>1         </td><td>0       </td><td>300     </td><td>cnn      </td><td>0.9611</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-patience.json                                                   </td><td>28000        </td><td>1            </td><td>5       </td><td>10         </td><td>128        </td><td>1         </td><td>100     </td><td>300     </td><td>cnn      </td><td>0.9648</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-patience.json                                                   </td><td>28000        </td><td>1            </td><td>5       </td><td>10         </td><td>128        </td><td>1         </td><td>100     </td><td>300     </td><td>rnn      </td><td>0.9681</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-nowemb.json                                                     </td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>128        </td><td>1         </td><td>0       </td><td>300     </td><td>rnn      </td><td>0.9686</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-RNN.json                                                            </td><td>28000        </td><td>1            </td><td>8       </td><td>10         </td><td>128        </td><td>1         </td><td>100     </td><td>300     </td><td>rnn      </td><td>0.9707</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-CNN.json                                                            </td><td>28000        </td><td>1            </td><td>8       </td><td>10         </td><td>128        </td><td>1         </td><td>100     </td><td>300     </td><td>cnn      </td><td>0.9707</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-CNN-lrpatience.json                                                 </td><td>28000        </td><td>1            </td><td>7       </td><td>4          </td><td>128        </td><td>1         </td><td>100     </td><td>300     </td><td>cnn      </td><td>0.9736</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb_200-hidden_256.json                                   </td><td>20000        </td><td>5            </td><td>7       </td><td>4          </td><td>256        </td><td>1         </td><td>200     </td><td>300     </td><td>rnn      </td><td>0.975 </td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400.json</td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>384        </td><td>2         </td><td>0       </td><td>400     </td><td>rnn      </td><td>0.9753</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500.json     </td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>384        </td><td>1         </td><td>0       </td><td>500     </td><td>rnn      </td><td>0.9753</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-CNN_vs_RNN-RNN-lrpatience.json                                                 </td><td>28000        </td><td>1            </td><td>7       </td><td>4          </td><td>128        </td><td>1         </td><td>100     </td><td>300     </td><td>rnn      </td><td>0.9753</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400.json     </td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>384        </td><td>1         </td><td>0       </td><td>400     </td><td>rnn      </td><td>0.9754</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256.json                                     </td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>256        </td><td>1         </td><td>0       </td><td>300     </td><td>rnn      </td><td>0.9759</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb-hidden_256.json                                       </td><td>20000        </td><td>5            </td><td>7       </td><td>4          </td><td>256        </td><td>1         </td><td>100     </td><td>300     </td><td>rnn      </td><td>0.9762</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500.json     </td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>256        </td><td>1         </td><td>0       </td><td>500     </td><td>rnn      </td><td>0.9764</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-layers_2.json                            </td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>256        </td><td>2         </td><td>0       </td><td>300     </td><td>rnn      </td><td>0.9765</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-cemb_400.json                            </td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>256        </td><td>1         </td><td>0       </td><td>400     </td><td>rnn      </td><td>0.9767</td></tr>\n",
       "<tr><td>./configs/1.4.4.a-RNN-cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400.json</td><td>20000        </td><td>1            </td><td>7       </td><td>4          </td><td>256        </td><td>2         </td><td>0       </td><td>400     </td><td>rnn      </td><td>0.9771</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllllll}\n",
      "\\hline\n",
      " word\\_max\\_size & word\\_min\\_freq & patience & lr\\_patience & hidden\\_size & num\\_layers & wemb\\_dim & cemb\\_dim & cemb\\_type & score  \\\\\n",
      " 20000         & 1             & 7        & 4           & 128         & 1          & 0        & 300      & cnn       & 0.9611 \\\\\n",
      " 28000         & 1             & 5        & 10          & 128         & 1          & 100      & 300      & cnn       & 0.9648 \\\\\n",
      " 28000         & 1             & 5        & 10          & 128         & 1          & 100      & 300      & rnn       & 0.9681 \\\\\n",
      " 20000         & 1             & 7        & 4           & 128         & 1          & 0        & 300      & rnn       & 0.9686 \\\\\n",
      " 28000         & 1             & 8        & 10          & 128         & 1          & 100      & 300      & rnn       & 0.9707 \\\\\n",
      " 28000         & 1             & 8        & 10          & 128         & 1          & 100      & 300      & cnn       & 0.9707 \\\\\n",
      " 28000         & 1             & 7        & 4           & 128         & 1          & 100      & 300      & cnn       & 0.9736 \\\\\n",
      " 20000         & 5             & 7        & 4           & 256         & 1          & 200      & 300      & rnn       & 0.975  \\\\\n",
      " 20000         & 1             & 7        & 4           & 384         & 2          & 0        & 400      & rnn       & 0.9753 \\\\\n",
      " 20000         & 1             & 7        & 4           & 384         & 1          & 0        & 500      & rnn       & 0.9753 \\\\\n",
      " 28000         & 1             & 7        & 4           & 128         & 1          & 100      & 300      & rnn       & 0.9753 \\\\\n",
      " 20000         & 1             & 7        & 4           & 384         & 1          & 0        & 400      & rnn       & 0.9754 \\\\\n",
      " 20000         & 1             & 7        & 4           & 256         & 1          & 0        & 300      & rnn       & 0.9759 \\\\\n",
      " 20000         & 5             & 7        & 4           & 256         & 1          & 100      & 300      & rnn       & 0.9762 \\\\\n",
      " 20000         & 1             & 7        & 4           & 256         & 1          & 0        & 500      & rnn       & 0.9764 \\\\\n",
      " 20000         & 1             & 7        & 4           & 256         & 2          & 0        & 300      & rnn       & 0.9765 \\\\\n",
      " 20000         & 1             & 7        & 4           & 256         & 1          & 0        & 400      & rnn       & 0.9767 \\\\\n",
      " 20000         & 1             & 7        & 4           & 256         & 2          & 0        & 400      & rnn       & 0.9771 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "all_keys = defaultdict(set)\n",
    "\n",
    "def get_values(dic, prefix=None):\n",
    "    \"\"\" This function flattens a dictionary\n",
    "    \"\"\"\n",
    "    if not prefix:\n",
    "        prefix = []\n",
    "    if isinstance(dic, list):\n",
    "        for index, value in enumerate(dic):\n",
    "            yield from get_values(value, prefix=prefix+[str(index)])\n",
    "    elif isinstance(dic, dict):\n",
    "        for key, value in dic.items():\n",
    "            yield from get_values(value, prefix=prefix+[key])\n",
    "    else:\n",
    "        yield (\"%\".join(prefix), dic)\n",
    "\n",
    "# Parse all JSON FILES\n",
    "json_files = []\n",
    "for config in glob.glob(\"./configs/*.json\"):\n",
    "    with open(config) as f:\n",
    "        json_files.append(json.load(f))\n",
    "        json_files[-1][\"config_path\"] = config\n",
    "        \n",
    "## For each one, add the value to all_keys\n",
    "for data in json_files:\n",
    "    for key, value in get_values(data):\n",
    "        all_keys[key].add(value)\n",
    "\n",
    "\n",
    "def get_best_score(x):\n",
    "    if x[0] in best:\n",
    "        return best[x[0]].acc\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "columns = [\"config_path\"] + [\n",
    "    key \n",
    "    for key, value in all_keys.items()\n",
    "    if len(value) > 1 and key not in (\"modelname\", \"config_path\")\n",
    "]\n",
    "table_models = []\n",
    "for data in json_files:\n",
    "    dic = dict(get_values(data))\n",
    "    table_models.append([\n",
    "        dic[key]\n",
    "        for key in columns\n",
    "    ] + [best[dic[\"config_path\"]].acc])\n",
    "\n",
    "table_models = sorted(table_models, key=lambda x: x[-1])\n",
    "\n",
    "display(HTML(tabulate.tabulate([columns+[\"score\"]] + table_models, tablefmt='html')))\n",
    "\n",
    "\n",
    "print(tabulate.tabulate([\n",
    "    columns[1:]+[\"score\"]\n",
    "] + [\n",
    "    t[1:]\n",
    "    for t in table_models\n",
    "], tablefmt='latex'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
