{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectif\n",
    "\n",
    "L'objectif de ce notebook est de créer les configurations à évaluer.\n",
    "\n",
    "On séparera les études de configuration de lemmatisation et de tâches morpho-syntaxiques.\n",
    "\n",
    "## Configurations Lemmatisation\n",
    "\n",
    "Options ayant un impact:\n",
    "\n",
    "- CEMB DIM\n",
    "- CEMB TYPE\n",
    "- CEMB LAYERS\n",
    "- LEARNING RATES\n",
    "\n",
    "```json\n",
    "{\n",
    "    // Output information\n",
    "    \"modelname\": \"latest-lasla-lat\",\n",
    "    \"modelpath\": \"./models/\",\n",
    "    // Run information\n",
    "    \"run_test\": true,\n",
    "    // Input data information\n",
    "    \"input_path\": \"./datasets/lat/better-corpus/train.tsv\",\n",
    "    \"test_path\": \"./datasets/lat/better-corpus/test.tsv\",\n",
    "    \"dev_path\": \"./datasets/lat/better-corpus/dev.tsv\",\n",
    "    \"header\": true,\n",
    "    \"sep\": \"\\t\",\n",
    "    \"breakline_ref\": \"pos\", // Not used here because empty lines mark sequence changes\n",
    "    \"breakline_data\": \"NONE\", // Not used here\n",
    "    // Input metrics\n",
    "    \"char_max_size\": 500,\n",
    "    \"word_max_size\": 28000,\n",
    "    \"max_sent_len\": 35,\n",
    "    \"max_sents\": 1000000,\n",
    "    \"char_min_freq\": 1,\n",
    "    \"word_min_freq\": 1,\n",
    "    // Use EOS and BOS\n",
    "    \"char_eos\": true,\n",
    "    \"char_bos\": true,\n",
    "    // Tasks\n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"name\": \"lemma\",\n",
    "            \"target\": true,\n",
    "            \"context\": \"sentence\",\n",
    "            \"level\": \"char\",\n",
    "            \"decoder\": \"attentional\",\n",
    "            \"settings\": {\n",
    "                \"bos\": true,\n",
    "                \"eos\": true,\n",
    "                \"lower\": true,\n",
    "                \"target\": \"lemma\"\n",
    "            },\n",
    "            \"layer\": -1\n",
    "        },\n",
    "        //[{\"name\": task} for task in tasks]\n",
    "    ],\n",
    "    \"task_defaults\": {\n",
    "        \"level\": \"token\",\n",
    "        \"layer\": -1,\n",
    "        \"decoder\": \"linear\",\n",
    "        \"context\": \"sentence\"\n",
    "    },\n",
    "    \n",
    "    \"patience\": 8,\n",
    "    \"factor\": 0.5,\n",
    "    \"threshold\": 0.00001,\n",
    "    \"min_weight\": 0.2,\n",
    "    \n",
    "    // Language Model Information\n",
    "    \"include_lm\": true,\n",
    "    \"lm_shared_softmax\": true,\n",
    "    \"lm_schedule\": {\n",
    "        \"patience\": 2,\n",
    "        \"factor\": 0.5,\n",
    "        \"weight\": 0.2,\n",
    "        \"mode\": \"min\"\n",
    "    },\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 100,\n",
    "    \"dropout\": 0.25,\n",
    "    \"word_dropout\": 0,\n",
    "    // Learning rate update\n",
    "    \"lr\": 0.001,\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"lr_patience\": 10,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"clip_norm\": 5,\n",
    "    \n",
    "    // Tache linéaires\n",
    "    \"linear_layers\": 1,\n",
    "    // Tache linéaires: Encodeur\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 1,\n",
    "    \"cell\": \"GRU\",\n",
    "    // Taches linéaires: Word Embedding et Mixer\n",
    "    \"wemb_dim\": 100,\n",
    "    \"merge_type\": \"concat\",\n",
    "    // Lemmatisation : Decoder et CEMB\n",
    "    \"cemb_dim\": 300,\n",
    "    \"cemb_type\": \"rnn\",\n",
    "    \"cemb_layers\": 2,\n",
    "    \"decoder_layers\": 3, // Would be nice ?\n",
    "    \"custom_cemb_cell\": false,\n",
    "    // Training options\n",
    "    \"checks_per_epoch\": 1,\n",
    "    \"report_freq\": 200,\n",
    "    \"verbose\": true,\n",
    "    \"device\": \"cuda\",\n",
    "    \"buffer_size\": 10000,  // Sentence in memory\n",
    "    \"minimize_pad\": false,\n",
    "    \"shuffle\": true,\n",
    "    \"pretrain_embeddings\": false,\n",
    "    \"load_pretrained_embeddings\": \"\",\n",
    "    \"load_pretrained_encoder\": \"\",\n",
    "    \"freeze_embeddings\": false,\n",
    "    \"scorer\": \"general\"\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import copy\\n\\nCNN = copy.deepcopy(data)\\nRNN = copy.deepcopy(data)\\n\\nCNN[\"modelname\"] = \"cemb_CNN_-\"\\nRNN[\"modelname\"] = \"cemb_RNN_-\"\\n\\nwith open(\"./configs/1.4.4.a-CNN_vs_RNN-CNN.json\", \"w\") as f:\\n    json.dump(CNN, f)\\n\\nwith open(\"./configs/1.4.4.a-CNN_vs_RNN-RNN.json\", \"w\") as f:\\n    json.dump(RNN, f)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In[len(In)-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.loads(\n",
    "    \"\\n\".join(\n",
    "        [\n",
    "            line.split(\"//\")[0]\n",
    "            for line in \"\"\"{\n",
    "            // Output information\n",
    "            \"modelname\": \"latest-lasla-lat\",\n",
    "            \"modelpath\": \"./models/\",\n",
    "            // Run information\n",
    "            \"run_test\": true,\n",
    "            // Input data information\n",
    "            \"input_path\": \"./mood-tense-voice-pft/train.tsv\",\n",
    "            \"test_path\": \"./mood-tense-voice-pft/test.tsv\",\n",
    "            \"dev_path\": \"./mood-tense-voice-pft/dev.tsv\",\n",
    "            \"header\": true,\n",
    "            \"sep\": \"\\\\t\",\n",
    "            \"breakline_ref\": \"pos\", // Not used here because empty lines mark sequence changes\n",
    "            \"breakline_data\": \"NONE\", // Not used here\n",
    "            // Input metrics\n",
    "            \"char_max_size\": 500,\n",
    "            \"word_max_size\": 28000,\n",
    "            \"max_sent_len\": 35,\n",
    "            \"max_sents\": 1000000,\n",
    "            \"char_min_freq\": 1,\n",
    "            \"word_min_freq\": 1,\n",
    "            // Use EOS and BOS\n",
    "            \"char_eos\": true,\n",
    "            \"char_bos\": true,\n",
    "            // Tasks\n",
    "            \"tasks\": [\n",
    "                {\n",
    "                    \"name\": \"lemma\",\n",
    "                    \"target\": true,\n",
    "                    \"context\": \"sentence\",\n",
    "                    \"level\": \"char\",\n",
    "                    \"decoder\": \"attentional\",\n",
    "                    \"settings\": {\n",
    "                        \"bos\": true,\n",
    "                        \"eos\": true,\n",
    "                        \"lower\": true,\n",
    "                        \"target\": \"lemma\"\n",
    "                    },\n",
    "                    \"layer\": -1\n",
    "                }//,\n",
    "                //[{\"name\": task} for task in tasks]\n",
    "            ],\n",
    "            \"task_defaults\": {\n",
    "                \"level\": \"token\",\n",
    "                \"layer\": -1,\n",
    "                \"decoder\": \"linear\",\n",
    "                \"context\": \"sentence\"\n",
    "            },\n",
    "\n",
    "            \"patience\": 5,\n",
    "            \"factor\": 0.5,\n",
    "            \"threshold\": 0,\n",
    "            \"min_weight\": 0,\n",
    "\n",
    "            // Language Model Information\n",
    "            \"include_lm\": true,\n",
    "            \"lm_shared_softmax\": true,\n",
    "            \"lm_schedule\": {\n",
    "                \"patience\": 2,\n",
    "                \"factor\": 0.5,\n",
    "                \"weight\": 0.2,\n",
    "                \"mode\": \"min\"\n",
    "            },\n",
    "            \"batch_size\": 256,\n",
    "            \"epochs\": 100,\n",
    "            \"dropout\": 0.25,\n",
    "            \"word_dropout\": 0,\n",
    "            // Learning rate update\n",
    "            \"lr\": 0.001,\n",
    "            \"lr_factor\": 0.75,\n",
    "            \"lr_patience\": 2,\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"clip_norm\": 5,\n",
    "\n",
    "            // Tache linéaires\n",
    "            \"linear_layers\": 1,\n",
    "            // Tache linéaires: Encodeur\n",
    "            \"hidden_size\": 128,\n",
    "            \"num_layers\": 1,\n",
    "            \"cell\": \"GRU\",\n",
    "            // Taches linéaires: Word Embedding et Mixer\n",
    "            \"wemb_dim\": 100,\n",
    "            \"merge_type\": \"concat\",\n",
    "            // Lemmatisation : Decoder et CEMB\n",
    "            \"cemb_dim\": 300,\n",
    "            \"cemb_type\": \"rnn\",\n",
    "            \"cemb_layers\": 2,\n",
    "            \"decoder_layers\": 3, // Would be nice ?\n",
    "            \"custom_cemb_cell\": false,\n",
    "            // Training options\n",
    "            \"checks_per_epoch\": 1,\n",
    "            \"report_freq\": 200,\n",
    "            \"verbose\": true,\n",
    "            \"device\": \"cuda\",\n",
    "            \"buffer_size\": 10000,  // Sentence in memory\n",
    "            \"minimize_pad\": false,\n",
    "            \"shuffle\": true,\n",
    "            \"pretrain_embeddings\": false,\n",
    "            \"load_pretrained_embeddings\": \"\",\n",
    "            \"load_pretrained_encoder\": \"\",\n",
    "            \"freeze_embeddings\": false,\n",
    "            \"scorer\": \"general\"\n",
    "        }\n",
    "        \"\"\".split(\"\\n\") \n",
    "                             if not line.strip().startswith(\"//\") and line.strip()\n",
    "                            ]\n",
    "                           )\n",
    "                 )  # json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tasks\n",
    "with open(\"/home/thibault/dev/LASLA/mood-tense-voice-pft/test.tsv\") as f:\n",
    "    for line in f:\n",
    "        break\n",
    "data[\"tasks\"].extend([\n",
    "    {\"name\": task}\n",
    "    for task in line.split()\n",
    "    if task not in (\"lemma\", \"token\", \"Dis\", \"Entity\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First test: CNN vs RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "CNN = copy.deepcopy(data)\n",
    "RNN = copy.deepcopy(data)\n",
    "\n",
    "CNN[\"modelname\"] = \"cemb_CNN_-\"\n",
    "RNN[\"modelname\"] = \"cemb_RNN_-\"\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-CNN.json\", \"w\") as f:\n",
    "    json.dump(CNN, f)\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-RNN.json\", \"w\") as f:\n",
    "    json.dump(RNN, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
