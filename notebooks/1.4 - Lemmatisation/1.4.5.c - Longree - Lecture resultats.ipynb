{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectifs\n",
    "\n",
    "- Lire les résultats des tests sur les 4 fichiers pour les corpus d'entraînement de D Longrée.\n",
    "- Ajouter le nombre de tokens par corpus en lisant le fichier CSV lié ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "re_mname = re.compile(r\"(?:model-longree-simpler-reprod-longree-simpler-|model-percent-reprod-longree-)([\\w-]+)\")\n",
    "re_sub = re.compile(r\"^([\\w-]+):$\")\n",
    "re_metric = re.compile(r\"^([\\w-]+): ([\\d\\.]+)$\")\n",
    "def get_model_name(model_name):\n",
    "    cnn_layer = \"2\"\n",
    "    if \"simpler\" in model_name:\n",
    "        cnn_layer = \"1\"\n",
    "    grp = re_mname.findall(model_name)[0]\n",
    "    return grp, cnn_layer \n",
    "\n",
    "#results = {\n",
    "    #models : {\n",
    "    #  {test-file: {metric: score}}\n",
    "    #}\n",
    "#}\n",
    "\n",
    "results = defaultdict( # Key: Task\n",
    "    lambda: defaultdict( # Key : model\n",
    "        lambda: defaultdict( # Key : layers\n",
    "            lambda: defaultdict( # Key : Test\n",
    "                lambda: defaultdict( # Key Subtask\n",
    "                    lambda: defaultdict( # Key Metric\n",
    "                        str\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "header = [[\"model\", \"layers\"]]\n",
    "tests = []\n",
    "metrics = []\n",
    "models = []\n",
    "tasks = defaultdict(list)\n",
    "\n",
    "for file in glob.glob(\"/home/thibault/CloudStation/Thèse/Modeles/Resultats/Longree/*.txt\"):\n",
    "    basename = os.path.basename(file)\n",
    "    model, test, _ = basename.split(\"_-_\")\n",
    "    model, date = model.split(\"---\")\n",
    "    model, layers = get_model_name(model)\n",
    "    if (model, layers) not in models:\n",
    "        models.append((model, layers))\n",
    "    \n",
    "    if test not in tests:\n",
    "        tests.append(test)\n",
    "        \n",
    "    with open(file) as f:\n",
    "        task, subtask = None, None\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"::: Evaluation report for task: \"):\n",
    "                task = line[len(\"::: Evaluation report for task: \"): -4]\n",
    "                continue\n",
    "                \n",
    "            if re_sub.match(line):\n",
    "                subtask = re_sub.findall(line)[0]\n",
    "                continue\n",
    "                \n",
    "            if re_metric.match(line):\n",
    "                metric, number = re_metric.findall(line)[0]\n",
    "                if (subtask, metric) not in tasks[task]:\n",
    "                    tasks[task].append((subtask, metric))\n",
    "                results[task][model][layers][test][subtask][metric] = number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "for task, metrics in tasks.items():\n",
    "    header = [\"model\", \"layers\", \"test\"] + [\"/\".join(m) for m in metrics]\n",
    "    rows = [header]\n",
    "    for test in sorted(tests):\n",
    "        for model, layer in sorted(models, key=lambda x: x[0]+x[1]):\n",
    "            row = [model, layer, test]\n",
    "            for subtask, metric in metrics:\n",
    "                row.append(results[task][model][layer][test][subtask][metric])\n",
    "            rows.append(row)\n",
    "    with open(\"longree-result-\"+task+\".csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
