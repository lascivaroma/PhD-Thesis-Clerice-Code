{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensibilité des résultats en fonction de la taille du corpus d'entraînement\n",
    "\n",
    "On applique une coupe au corpus d'entraînement de 1%, 2%, 5%, etc.\n",
    "\n",
    "En fonction de cette coupe, on analyse le résultat sur trois tâches: \n",
    "- la lemmatisation car elle est la tâche centrale du lemmatiseur,\n",
    "- la POS car elle nécessite une compréhension de la syntaxe et du vocabulaire,\n",
    "- le genre car elle nécessite une approche morphologique.\n",
    "\n",
    "On obtient les coupes suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "from collections import defaultdict\n",
    "\n",
    "toks = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "files = []\n",
    "for file in sorted(list(glob.glob(\"../../../LASLA/0.*.txt\"))):\n",
    "    percent = os.path.basename(file).replace(\".txt\", \"\")\n",
    "    files.append(percent)\n",
    "    with open(file) as f:\n",
    "        train = False\n",
    "        started = False\n",
    "        for line in f:\n",
    "            # We look for the first iteration of train\n",
    "            # and then the first iteration of started\n",
    "            if not train:\n",
    "                train = line.strip() == \"train\"\n",
    "                continue\n",
    "            if not started:\n",
    "                started = line.strip().split() == [\"File\", \"Chunks\", \"Tokens\"]\n",
    "                continue\n",
    "            if line.strip() == \"# train's statistics\":\n",
    "                break\n",
    "            text, chunks, tokens = line.strip().split()\n",
    "            text = text.replace(\".tsv\", \"\")\n",
    "            if text[-1].isnumeric():\n",
    "                text = text[:-1]\n",
    "            # Reduce by author to have a manageable list\n",
    "            author = text.split(\"_\")[0]\n",
    "            toks[author][percent] += int(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>             </td><td style=\"text-align: right;\">    0.01</td><td style=\"text-align: right;\">    0.05</td><td style=\"text-align: right;\">     0.075</td><td style=\"text-align: right;\">     0.1</td><td style=\"text-align: right;\">     0.2</td><td style=\"text-align: right;\">     0.4</td><td style=\"text-align: right;\">     0.6</td><td style=\"text-align: right;\">     0.8        </td></tr>\n",
       "<tr><td>Caesar       </td><td style=\"text-align: right;\">  827   </td><td style=\"text-align: right;\"> 3576   </td><td style=\"text-align: right;\">  5210    </td><td style=\"text-align: right;\">  7023  </td><td style=\"text-align: right;\"> 13642  </td><td style=\"text-align: right;\"> 28654  </td><td style=\"text-align: right;\"> 43006  </td><td style=\"text-align: right;\"> 56210          </td></tr>\n",
       "<tr><td>Cato         </td><td style=\"text-align: right;\">  238   </td><td style=\"text-align: right;\"> 1076   </td><td style=\"text-align: right;\">  1450    </td><td style=\"text-align: right;\">  1873  </td><td style=\"text-align: right;\">  4138  </td><td style=\"text-align: right;\">  7113  </td><td style=\"text-align: right;\"> 10221  </td><td style=\"text-align: right;\"> 13426          </td></tr>\n",
       "<tr><td>Catullus     </td><td style=\"text-align: right;\">  171   </td><td style=\"text-align: right;\">  626   </td><td style=\"text-align: right;\">   802    </td><td style=\"text-align: right;\">  1098  </td><td style=\"text-align: right;\">  2233  </td><td style=\"text-align: right;\">  4257  </td><td style=\"text-align: right;\">  6283  </td><td style=\"text-align: right;\">  9206          </td></tr>\n",
       "<tr><td>Cicero       </td><td style=\"text-align: right;\"> 6861   </td><td style=\"text-align: right;\">27012   </td><td style=\"text-align: right;\"> 38738    </td><td style=\"text-align: right;\"> 49070  </td><td style=\"text-align: right;\"> 92026  </td><td style=\"text-align: right;\">171129  </td><td style=\"text-align: right;\">250420  </td><td style=\"text-align: right;\">330028          </td></tr>\n",
       "<tr><td>Curtius      </td><td style=\"text-align: right;\">  652   </td><td style=\"text-align: right;\"> 3191   </td><td style=\"text-align: right;\">  4534    </td><td style=\"text-align: right;\">  6190  </td><td style=\"text-align: right;\"> 12564  </td><td style=\"text-align: right;\"> 24348  </td><td style=\"text-align: right;\"> 37070  </td><td style=\"text-align: right;\"> 50085          </td></tr>\n",
       "<tr><td>Hirtius      </td><td style=\"text-align: right;\">   82   </td><td style=\"text-align: right;\">  325   </td><td style=\"text-align: right;\">   470    </td><td style=\"text-align: right;\">   630  </td><td style=\"text-align: right;\">  1281  </td><td style=\"text-align: right;\">  2399  </td><td style=\"text-align: right;\">  3539  </td><td style=\"text-align: right;\">  4572          </td></tr>\n",
       "<tr><td>Horatius     </td><td style=\"text-align: right;\">  487   </td><td style=\"text-align: right;\"> 2257   </td><td style=\"text-align: right;\">  3356    </td><td style=\"text-align: right;\">  4267  </td><td style=\"text-align: right;\">  8181  </td><td style=\"text-align: right;\"> 16072  </td><td style=\"text-align: right;\"> 23916  </td><td style=\"text-align: right;\"> 32172          </td></tr>\n",
       "<tr><td>Juvenalis    </td><td style=\"text-align: right;\">  311   </td><td style=\"text-align: right;\"> 1008   </td><td style=\"text-align: right;\">  1405    </td><td style=\"text-align: right;\">  1953  </td><td style=\"text-align: right;\">  4141  </td><td style=\"text-align: right;\">  8118  </td><td style=\"text-align: right;\"> 12599  </td><td style=\"text-align: right;\"> 17167          </td></tr>\n",
       "<tr><td>Lucretius    </td><td style=\"text-align: right;\">  846   </td><td style=\"text-align: right;\"> 2838   </td><td style=\"text-align: right;\">  4001    </td><td style=\"text-align: right;\">  5074  </td><td style=\"text-align: right;\">  9342  </td><td style=\"text-align: right;\"> 18545  </td><td style=\"text-align: right;\"> 27496  </td><td style=\"text-align: right;\"> 35730          </td></tr>\n",
       "<tr><td>Ovidius      </td><td style=\"text-align: right;\"> 1114   </td><td style=\"text-align: right;\"> 4819   </td><td style=\"text-align: right;\">  7106    </td><td style=\"text-align: right;\">  9497  </td><td style=\"text-align: right;\"> 17872  </td><td style=\"text-align: right;\"> 35893  </td><td style=\"text-align: right;\"> 53720  </td><td style=\"text-align: right;\"> 71495          </td></tr>\n",
       "<tr><td>Persius      </td><td style=\"text-align: right;\">   56   </td><td style=\"text-align: right;\">  139   </td><td style=\"text-align: right;\">   247    </td><td style=\"text-align: right;\">   379  </td><td style=\"text-align: right;\">   760  </td><td style=\"text-align: right;\">  1526  </td><td style=\"text-align: right;\">  2442  </td><td style=\"text-align: right;\">  3324          </td></tr>\n",
       "<tr><td>Petronius    </td><td style=\"text-align: right;\">  414   </td><td style=\"text-align: right;\"> 1618   </td><td style=\"text-align: right;\">  2408    </td><td style=\"text-align: right;\">  3219  </td><td style=\"text-align: right;\">  5672  </td><td style=\"text-align: right;\"> 10086  </td><td style=\"text-align: right;\"> 15451  </td><td style=\"text-align: right;\"> 21532          </td></tr>\n",
       "<tr><td>Plautus      </td><td style=\"text-align: right;\">  898   </td><td style=\"text-align: right;\"> 3509   </td><td style=\"text-align: right;\">  5147    </td><td style=\"text-align: right;\">  6479  </td><td style=\"text-align: right;\"> 11695  </td><td style=\"text-align: right;\"> 21825  </td><td style=\"text-align: right;\"> 31516  </td><td style=\"text-align: right;\"> 41821          </td></tr>\n",
       "<tr><td>Plinius      </td><td style=\"text-align: right;\">  978   </td><td style=\"text-align: right;\"> 3920   </td><td style=\"text-align: right;\">  5734    </td><td style=\"text-align: right;\">  7686  </td><td style=\"text-align: right;\"> 15271  </td><td style=\"text-align: right;\"> 30923  </td><td style=\"text-align: right;\"> 46081  </td><td style=\"text-align: right;\"> 60698          </td></tr>\n",
       "<tr><td>Propertius   </td><td style=\"text-align: right;\">  324   </td><td style=\"text-align: right;\"> 1353   </td><td style=\"text-align: right;\">  1986    </td><td style=\"text-align: right;\">  2732  </td><td style=\"text-align: right;\">  4997  </td><td style=\"text-align: right;\">  9602  </td><td style=\"text-align: right;\"> 14063  </td><td style=\"text-align: right;\"> 18550          </td></tr>\n",
       "<tr><td>PseudoCaesar1</td><td style=\"text-align: right;\">  113   </td><td style=\"text-align: right;\">  540   </td><td style=\"text-align: right;\">   761    </td><td style=\"text-align: right;\">  1081  </td><td style=\"text-align: right;\">  2371  </td><td style=\"text-align: right;\">  4822  </td><td style=\"text-align: right;\">  7219  </td><td style=\"text-align: right;\">  9660          </td></tr>\n",
       "<tr><td>PseudoCaesar2</td><td style=\"text-align: right;\">  140   </td><td style=\"text-align: right;\">  508   </td><td style=\"text-align: right;\">   743    </td><td style=\"text-align: right;\">   944  </td><td style=\"text-align: right;\">  1704  </td><td style=\"text-align: right;\">  3605  </td><td style=\"text-align: right;\">  5656  </td><td style=\"text-align: right;\">  7268          </td></tr>\n",
       "<tr><td>PseudoCaesar3</td><td style=\"text-align: right;\">   17   </td><td style=\"text-align: right;\">  173   </td><td style=\"text-align: right;\">   238    </td><td style=\"text-align: right;\">   323  </td><td style=\"text-align: right;\">   594  </td><td style=\"text-align: right;\">  1329  </td><td style=\"text-align: right;\">  2816  </td><td style=\"text-align: right;\">  4143          </td></tr>\n",
       "<tr><td>Sallustius   </td><td style=\"text-align: right;\">  432   </td><td style=\"text-align: right;\"> 1829   </td><td style=\"text-align: right;\">  2584    </td><td style=\"text-align: right;\">  3277  </td><td style=\"text-align: right;\">  6487  </td><td style=\"text-align: right;\"> 13051  </td><td style=\"text-align: right;\"> 20049  </td><td style=\"text-align: right;\"> 25986          </td></tr>\n",
       "<tr><td>Seneca       </td><td style=\"text-align: right;\"> 4022   </td><td style=\"text-align: right;\">16411   </td><td style=\"text-align: right;\"> 23377    </td><td style=\"text-align: right;\"> 30696  </td><td style=\"text-align: right;\"> 58990  </td><td style=\"text-align: right;\">113565  </td><td style=\"text-align: right;\">169081  </td><td style=\"text-align: right;\">223701          </td></tr>\n",
       "<tr><td>Tacitus      </td><td style=\"text-align: right;\"> 1945   </td><td style=\"text-align: right;\"> 8127   </td><td style=\"text-align: right;\"> 11727    </td><td style=\"text-align: right;\"> 15306  </td><td style=\"text-align: right;\"> 30107  </td><td style=\"text-align: right;\"> 59410  </td><td style=\"text-align: right;\"> 87996  </td><td style=\"text-align: right;\">117596          </td></tr>\n",
       "<tr><td>Tibullus     </td><td style=\"text-align: right;\">  163   </td><td style=\"text-align: right;\">  625   </td><td style=\"text-align: right;\">   939    </td><td style=\"text-align: right;\">  1158  </td><td style=\"text-align: right;\">  2352  </td><td style=\"text-align: right;\">  4314  </td><td style=\"text-align: right;\">  6924  </td><td style=\"text-align: right;\">  9218          </td></tr>\n",
       "<tr><td>Vergilius    </td><td style=\"text-align: right;\"> 1021   </td><td style=\"text-align: right;\"> 4062   </td><td style=\"text-align: right;\">  5885    </td><td style=\"text-align: right;\">  7851  </td><td style=\"text-align: right;\"> 15584  </td><td style=\"text-align: right;\"> 31652  </td><td style=\"text-align: right;\"> 47111  </td><td style=\"text-align: right;\"> 62639          </td></tr>\n",
       "<tr><td>Total        </td><td style=\"text-align: right;\">22112   </td><td style=\"text-align: right;\">89542   </td><td style=\"text-align: right;\">128848    </td><td style=\"text-align: right;\">167806  </td><td style=\"text-align: right;\">322004  </td><td style=\"text-align: right;\">622238  </td><td style=\"text-align: right;\">924675  </td><td style=\"text-align: right;\">     1.22623e+06</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\hline\n",
      "               &     0.01 &     0.05 &      0.075 &      0.1 &      0.2 &      0.4 &      0.6 &      0.8         \\\\\n",
      " Caesar        &   827    &  3576    &   5210     &   7023   &  13642   &  28654   &  43006   &  56210           \\\\\n",
      " Cato          &   238    &  1076    &   1450     &   1873   &   4138   &   7113   &  10221   &  13426           \\\\\n",
      " Catullus      &   171    &   626    &    802     &   1098   &   2233   &   4257   &   6283   &   9206           \\\\\n",
      " Cicero        &  6861    & 27012    &  38738     &  49070   &  92026   & 171129   & 250420   & 330028           \\\\\n",
      " Curtius       &   652    &  3191    &   4534     &   6190   &  12564   &  24348   &  37070   &  50085           \\\\\n",
      " Hirtius       &    82    &   325    &    470     &    630   &   1281   &   2399   &   3539   &   4572           \\\\\n",
      " Horatius      &   487    &  2257    &   3356     &   4267   &   8181   &  16072   &  23916   &  32172           \\\\\n",
      " Juvenalis     &   311    &  1008    &   1405     &   1953   &   4141   &   8118   &  12599   &  17167           \\\\\n",
      " Lucretius     &   846    &  2838    &   4001     &   5074   &   9342   &  18545   &  27496   &  35730           \\\\\n",
      " Ovidius       &  1114    &  4819    &   7106     &   9497   &  17872   &  35893   &  53720   &  71495           \\\\\n",
      " Persius       &    56    &   139    &    247     &    379   &    760   &   1526   &   2442   &   3324           \\\\\n",
      " Petronius     &   414    &  1618    &   2408     &   3219   &   5672   &  10086   &  15451   &  21532           \\\\\n",
      " Plautus       &   898    &  3509    &   5147     &   6479   &  11695   &  21825   &  31516   &  41821           \\\\\n",
      " Plinius       &   978    &  3920    &   5734     &   7686   &  15271   &  30923   &  46081   &  60698           \\\\\n",
      " Propertius    &   324    &  1353    &   1986     &   2732   &   4997   &   9602   &  14063   &  18550           \\\\\n",
      " PseudoCaesar1 &   113    &   540    &    761     &   1081   &   2371   &   4822   &   7219   &   9660           \\\\\n",
      " PseudoCaesar2 &   140    &   508    &    743     &    944   &   1704   &   3605   &   5656   &   7268           \\\\\n",
      " PseudoCaesar3 &    17    &   173    &    238     &    323   &    594   &   1329   &   2816   &   4143           \\\\\n",
      " Sallustius    &   432    &  1829    &   2584     &   3277   &   6487   &  13051   &  20049   &  25986           \\\\\n",
      " Seneca        &  4022    & 16411    &  23377     &  30696   &  58990   & 113565   & 169081   & 223701           \\\\\n",
      " Tacitus       &  1945    &  8127    &  11727     &  15306   &  30107   &  59410   &  87996   & 117596           \\\\\n",
      " Tibullus      &   163    &   625    &    939     &   1158   &   2352   &   4314   &   6924   &   9218           \\\\\n",
      " Vergilius     &  1021    &  4062    &   5885     &   7851   &  15584   &  31652   &  47111   &  62639           \\\\\n",
      " Total         & 22112    & 89542    & 128848     & 167806   & 322004   & 622238   & 924675   &      1.22623e+06 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Create a table like representation\n",
    "import tabulate\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "keys = sorted(list(toks.keys()))\n",
    "\n",
    "rows = [\n",
    "    [\"\"] + [file for file in files]\n",
    "]\n",
    "\n",
    "total = {file: 0 for file in files}\n",
    "\n",
    "for key in keys:\n",
    "    rows.append([key])\n",
    "    rows[-1].extend([toks[key][file] for file in files])\n",
    "    for file in files:\n",
    "        total[file] += toks[key][file]\n",
    "\n",
    "rows.append([\"Total\"]  + [total[file] for file in files])\n",
    "\n",
    "display(HTML(tabulate.tabulate(rows, tablefmt='html')))\n",
    "\n",
    "print(tabulate.tabulate(rows, tablefmt='latex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the configuration files for all files\n",
    "import json\n",
    "\n",
    "BASE_CONFIG = json.loads(\"\"\"{\n",
    "    \"modelname\": \"model-percent-{}-\",\n",
    "    \"modelpath\": \"./models/\",\n",
    "    \"run_test\": false,\n",
    "    \"max_sent_len\": 35,\n",
    "    \"max_sents\": 1000000,\n",
    "    \"input_path\": \"./protogenie-partial/{per}train.tsv\",\n",
    "    \"test_path\": \"./protogenie-partial/{per}test.tsv\",\n",
    "    \"dev_path\": \"./protogenie-partial/{per}dev.tsv\",\n",
    "    \"breakline_ref\": \"pos\",\n",
    "    \"breakline_data\": \"$.\",\n",
    "    \"char_max_size\": 500,\n",
    "    \"word_max_size\": 20000,\n",
    "    \"char_min_freq\": 1,\n",
    "    \"word_min_freq\": 1,\n",
    "    \"char_eos\": true,\n",
    "    \"char_bos\": true,\n",
    "    \"header\": true,\n",
    "    \"sep\": \"\\\\t\",\n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"name\": \"lemma\",\n",
    "            \"target\": true,\n",
    "            \"context\": \"sentence\",\n",
    "            \"level\": \"char\",\n",
    "            \"decoder\": \"attentional\",\n",
    "            \"settings\": {\n",
    "                \"bos\": true,\n",
    "                \"eos\": true,\n",
    "                \"lower\": true,\n",
    "                \"target\": \"lemma\"\n",
    "            },\n",
    "            \"layer\": -1\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"pos\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Gend\"\n",
    "        }\n",
    "    ],\n",
    "    \"task_defaults\": {\n",
    "        \"level\": \"token\",\n",
    "        \"layer\": -1,\n",
    "        \"decoder\": \"linear\",\n",
    "        \"context\": \"sentence\"\n",
    "    },\n",
    "    \"patience\": 10,\n",
    "    \"factor\": 0.5,\n",
    "    \"threshold\": 0.0001,\n",
    "    \"min_weight\": 0.2,\n",
    "    \"include_lm\": true,\n",
    "    \"lm_shared_softmax\": true,\n",
    "    \"lm_schedule\": {\n",
    "        \"patience\": 2,\n",
    "        \"factor\": 0.5,\n",
    "        \"weight\": 0.2,\n",
    "        \"mode\": \"min\"\n",
    "    },\n",
    "    \"batch_size\": 256,\n",
    "    \"dropout\": 0.25,\n",
    "    \"lr\": 0.001,\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"lr_patience\": 8,\n",
    "    \"epochs\": 100,\n",
    "    \"cell\": \"GRU\",\n",
    "    \"num_layers\": 1,\n",
    "    \"hidden_size\": 128,\n",
    "    \"wemb_dim\": 100,\n",
    "    \"cemb_dim\": 300,\n",
    "    \"cemb_type\": \"rnn\",\n",
    "    \"cemb_layers\": 2,\n",
    "    \"checks_per_epoch\": 1,\n",
    "    \"report_freq\": 200,\n",
    "    \"verbose\": true,\n",
    "    \"device\": \"cuda\",\n",
    "    \"buffer_size\": 10000,\n",
    "    \"minimize_pad\": false,\n",
    "    \"word_dropout\": 0,\n",
    "    \"shuffle\": true,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"clip_norm\": 5,\n",
    "    \"pretrain_embeddings\": false,\n",
    "    \"load_pretrained_embeddings\": \"\",\n",
    "    \"load_pretrained_encoder\": \"\",\n",
    "    \"freeze_embeddings\": false,\n",
    "    \"custom_cemb_cell\": false,\n",
    "    \"merge_type\": \"concat\",\n",
    "    \"scorer\": \"general\",\n",
    "    \"linear_layers\": 1\n",
    "}\"\"\")\n",
    "\n",
    "import copy\n",
    "for file in files:\n",
    "    config = copy.deepcopy(BASE_CONFIG)\n",
    "    config[\"modelname\"] = config[\"modelname\"].format(file.replace(\".\", \",\"))\n",
    "    config[\"input_path\"] = config[\"input_path\"].format(per=file)\n",
    "    config[\"dev_path\"] = config[\"dev_path\"].format(per=file)\n",
    "    config[\"test_path\"] = config[\"test_path\"].format(per=file)\n",
    "    with open(\"../../../LASLA/configs/partial-{}.json\".format(file), \"w\") as f:\n",
    "        json.dump(config, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the configuration files for all files\n",
    "import json\n",
    "\n",
    "BASE_CONFIG = json.loads(\"\"\"{\n",
    "    \"modelname\": \"model-percent-simpler-{}-\",\n",
    "    \"modelpath\": \"./models/\",\n",
    "    \"run_test\": false,\n",
    "    \"max_sent_len\": 35,\n",
    "    \"max_sents\": 1000000,\n",
    "    \"input_path\": \"./protogenie-partial/{per}train.tsv\",\n",
    "    \"test_path\": \"./protogenie-partial/{per}test.tsv\",\n",
    "    \"dev_path\": \"./protogenie-partial/{per}dev.tsv\",\n",
    "    \"breakline_ref\": \"pos\",\n",
    "    \"breakline_data\": \"$.\",\n",
    "    \"char_max_size\": 500,\n",
    "    \"word_max_size\": 20000,\n",
    "    \"char_min_freq\": 1,\n",
    "    \"word_min_freq\": 1,\n",
    "    \"char_eos\": true,\n",
    "    \"char_bos\": true,\n",
    "    \"header\": true,\n",
    "    \"sep\": \"\\\\t\",\n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"name\": \"lemma\",\n",
    "            \"target\": true,\n",
    "            \"context\": \"sentence\",\n",
    "            \"level\": \"char\",\n",
    "            \"decoder\": \"attentional\",\n",
    "            \"settings\": {\n",
    "                \"bos\": true,\n",
    "                \"eos\": true,\n",
    "                \"lower\": true,\n",
    "                \"target\": \"lemma\"\n",
    "            },\n",
    "            \"layer\": -1\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"pos\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Gend\"\n",
    "        }\n",
    "    ],\n",
    "    \"task_defaults\": {\n",
    "        \"level\": \"token\",\n",
    "        \"layer\": -1,\n",
    "        \"decoder\": \"linear\",\n",
    "        \"context\": \"sentence\"\n",
    "    },\n",
    "    \"patience\": 8,\n",
    "    \"factor\": 0.5,\n",
    "    \"threshold\": 0.0001,\n",
    "    \"min_weight\": 0.2,\n",
    "    \"include_lm\": true,\n",
    "    \"lm_shared_softmax\": true,\n",
    "    \"lm_schedule\": {\n",
    "        \"patience\": 2,\n",
    "        \"factor\": 0.5,\n",
    "        \"weight\": 0.2,\n",
    "        \"mode\": \"min\"\n",
    "    },\n",
    "    \"batch_size\": 64,\n",
    "    \"dropout\": 0.25,\n",
    "    \"lr\": 0.001,\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"lr_patience\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"cell\": \"GRU\",\n",
    "    \"num_layers\": 1,\n",
    "    \"hidden_size\": 128,\n",
    "    \"wemb_dim\": 100,\n",
    "    \"cemb_dim\": 150,\n",
    "    \"cemb_type\": \"rnn\",\n",
    "    \"cemb_layers\": 1,\n",
    "    \"checks_per_epoch\": 1,\n",
    "    \"report_freq\": 200,\n",
    "    \"verbose\": true,\n",
    "    \"device\": \"cuda\",\n",
    "    \"buffer_size\": 10000,\n",
    "    \"minimize_pad\": false,\n",
    "    \"word_dropout\": 0,\n",
    "    \"shuffle\": true,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"clip_norm\": 5,\n",
    "    \"pretrain_embeddings\": false,\n",
    "    \"load_pretrained_embeddings\": \"\",\n",
    "    \"load_pretrained_encoder\": \"\",\n",
    "    \"freeze_embeddings\": false,\n",
    "    \"custom_cemb_cell\": false,\n",
    "    \"merge_type\": \"concat\",\n",
    "    \"scorer\": \"general\",\n",
    "    \"linear_layers\": 1\n",
    "}\"\"\")\n",
    "\n",
    "import copy\n",
    "for file in files:\n",
    "    config = copy.deepcopy(BASE_CONFIG)\n",
    "    config[\"modelname\"] = config[\"modelname\"].format(file.replace(\".\", \",\"))\n",
    "    config[\"input_path\"] = config[\"input_path\"].format(per=file)\n",
    "    config[\"test_path\"] = config[\"test_path\"].format(per=file)\n",
    "    config[\"dev_path\"] = config[\"dev_path\"].format(per=file)\n",
    "    with open(\"../../../LASLA/configs/partial-simpler-{}.json\".format(file), \"w\") as f:\n",
    "        json.dump(config, f)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
