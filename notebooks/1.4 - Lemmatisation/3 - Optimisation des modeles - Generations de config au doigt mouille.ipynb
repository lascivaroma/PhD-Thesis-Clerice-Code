{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectif\n",
    "\n",
    "L'objectif de ce notebook est de créer les configurations à évaluer.\n",
    "\n",
    "On séparera les études de configuration de lemmatisation et de tâches morpho-syntaxiques.\n",
    "\n",
    "## Configurations Lemmatisation\n",
    "\n",
    "Options ayant un impact:\n",
    "\n",
    "- CEMB DIM\n",
    "- CEMB TYPE\n",
    "- CEMB LAYERS\n",
    "- LEARNING RATES\n",
    "\n",
    "```json\n",
    "{\n",
    "    // Output information\n",
    "    \"modelname\": \"latest-lasla-lat\",\n",
    "    \"modelpath\": \"./models/\",\n",
    "    // No serialization\n",
    "    \"run_test\": false,\n",
    "    // Input data information\n",
    "    \"input_path\": \"./mood-tense-voice-pft/train.tsv\",\n",
    "    \"test_path\": \"./mood-tense-voice-pft/test.tsv\",\n",
    "    \"dev_path\": \"./mood-tense-voice-pft/dev.tsv\",\n",
    "    \"header\": true,\n",
    "    \"sep\": \"\\\\t\",\n",
    "    \"breakline_ref\": \"pos\", // Not used here because empty lines mark sequence changes\n",
    "    \"breakline_data\": \"NONE\", // Not used here\n",
    "    // Input metrics\n",
    "    \"char_max_size\": 500,\n",
    "    \"word_max_size\": 28000,\n",
    "    \"max_sent_len\": 35,\n",
    "    \"max_sents\": 1000000,\n",
    "    \"char_min_freq\": 1,\n",
    "    \"word_min_freq\": 1,\n",
    "    // Use EOS and BOS\n",
    "    \"char_eos\": true,\n",
    "    \"char_bos\": true,\n",
    "    // Tasks\n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"name\": \"lemma\",\n",
    "            \"target\": true,\n",
    "            \"context\": \"sentence\",\n",
    "            \"level\": \"char\",\n",
    "            \"decoder\": \"attentional\",\n",
    "            \"settings\": {\n",
    "                \"bos\": true,\n",
    "                \"eos\": true,\n",
    "                \"lower\": true,\n",
    "                \"target\": \"lemma\"\n",
    "            },\n",
    "            \"layer\": -1\n",
    "        }\n",
    "    ],\n",
    "    \"task_defaults\": {\n",
    "        \"level\": \"token\",\n",
    "        \"layer\": -1,\n",
    "        \"decoder\": \"linear\",\n",
    "        \"context\": \"sentence\"\n",
    "    },\n",
    "    \n",
    "    \"patience\": 8,\n",
    "    \"factor\": 0.5,\n",
    "    \"threshold\": 0.0001,\n",
    "    \"min_weight\": 0.2,\n",
    "    \n",
    "    // Language Model Information\n",
    "    \"include_lm\": true,\n",
    "    \"lm_shared_softmax\": true,\n",
    "    \"lm_schedule\": {\n",
    "        \"patience\": 2,\n",
    "        \"factor\": 0.5,\n",
    "        \"weight\": 0.2,\n",
    "        \"mode\": \"min\"\n",
    "    },\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 100,\n",
    "    \"dropout\": 0.25,\n",
    "    \"word_dropout\": 0,\n",
    "    // Learning rate update\n",
    "    \"lr\": 0.001,\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"lr_patience\": 10,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"clip_norm\": 5,\n",
    "    \n",
    "    // Tache linéaires\n",
    "    \"linear_layers\": 1,\n",
    "    // Tache linéaires: Encodeur\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 1,\n",
    "    \"cell\": \"GRU\",\n",
    "    // Taches linéaires: Word Embedding et Mixer\n",
    "    \"wemb_dim\": 100,\n",
    "    \"merge_type\": \"concat\",\n",
    "    // Lemmatisation : Decoder et CEMB\n",
    "    \"cemb_dim\": 300,\n",
    "    \"cemb_type\": \"rnn\",\n",
    "    \"cemb_layers\": 2,\n",
    "    \"decoder_layers\": 3, // Would be nice ?\n",
    "    \"custom_cemb_cell\": false,\n",
    "    // Training options\n",
    "    \"checks_per_epoch\": 1,\n",
    "    \"report_freq\": 200,\n",
    "    \"verbose\": true,\n",
    "    \"device\": \"cuda\",\n",
    "    \"buffer_size\": 10000,  // Sentence in memory\n",
    "    \"minimize_pad\": false,\n",
    "    \"shuffle\": true,\n",
    "    \"pretrain_embeddings\": false,\n",
    "    \"load_pretrained_embeddings\": \"\",\n",
    "    \"load_pretrained_encoder\": \"\",\n",
    "    \"freeze_embeddings\": false,\n",
    "    \"scorer\": \"general\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.loads(\n",
    "    \"\\n\".join(\n",
    "        [\n",
    "            line.split(\"//\")[0]\n",
    "            for line in \"\"\"{\n",
    "    // Output information\n",
    "    \"modelname\": \"latest-lasla-lat\",\n",
    "    \"modelpath\": \"./models/\",\n",
    "    // Run information\n",
    "    \"run_test\": false,\n",
    "    // Input data information\n",
    "    \"input_path\": \"./mood-tense-voice-pft/train.tsv\",\n",
    "    \"test_path\": \"./mood-tense-voice-pft/test.tsv\",\n",
    "    \"dev_path\": \"./mood-tense-voice-pft/dev.tsv\",\n",
    "    \"header\": true,\n",
    "    \"sep\": \"\\\\t\",\n",
    "    \"breakline_ref\": \"pos\", // Not used here because empty lines mark sequence changes\n",
    "    \"breakline_data\": \"NONE\", // Not used here\n",
    "    // Input metrics\n",
    "    \"char_max_size\": 500,\n",
    "    \"word_max_size\": 28000,\n",
    "    \"max_sent_len\": 35,\n",
    "    \"max_sents\": 1000000,\n",
    "    \"char_min_freq\": 1,\n",
    "    \"word_min_freq\": 1,\n",
    "    // Use EOS and BOS\n",
    "    \"char_eos\": true,\n",
    "    \"char_bos\": true,\n",
    "    // Tasks\n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"name\": \"lemma\",\n",
    "            \"target\": true,\n",
    "            \"context\": \"sentence\",\n",
    "            \"level\": \"char\",\n",
    "            \"decoder\": \"attentional\",\n",
    "            \"settings\": {\n",
    "                \"bos\": true,\n",
    "                \"eos\": true,\n",
    "                \"lower\": true,\n",
    "                \"target\": \"lemma\"\n",
    "            },\n",
    "            \"layer\": -1\n",
    "        }\n",
    "    ],\n",
    "    \"task_defaults\": {\n",
    "        \"level\": \"token\",\n",
    "        \"layer\": -1,\n",
    "        \"decoder\": \"linear\",\n",
    "        \"context\": \"sentence\"\n",
    "    },\n",
    "    \n",
    "    \"patience\": 8,\n",
    "    \"factor\": 0.5,\n",
    "    \"threshold\": 0.0001,\n",
    "    \"min_weight\": 0.2,\n",
    "    \n",
    "    // Language Model Information\n",
    "    \"include_lm\": true,\n",
    "    \"lm_shared_softmax\": true,\n",
    "    \"lm_schedule\": {\n",
    "        \"patience\": 2,\n",
    "        \"factor\": 0.5,\n",
    "        \"weight\": 0.2,\n",
    "        \"mode\": \"min\"\n",
    "    },\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 100,\n",
    "    \"dropout\": 0.25,\n",
    "    \"word_dropout\": 0,\n",
    "    // Learning rate update\n",
    "    \"lr\": 0.001,\n",
    "    \"lr_patience\": 10,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"clip_norm\": 5,\n",
    "    \n",
    "    // Tache linéaires\n",
    "    \"linear_layers\": 1,\n",
    "    // Tache linéaires: Encodeur\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 1,\n",
    "    \"cell\": \"GRU\",\n",
    "    // Taches linéaires: Word Embedding et Mixer\n",
    "    \"wemb_dim\": 100,\n",
    "    \"merge_type\": \"concat\",\n",
    "    // Lemmatisation : Decoder et CEMB\n",
    "    \"cemb_dim\": 300,\n",
    "    \"cemb_type\": \"rnn\",\n",
    "    \"cemb_layers\": 2,\n",
    "    \"decoder_layers\": 3, // Would be nice ?\n",
    "    \"custom_cemb_cell\": false,\n",
    "    // Training options\n",
    "    \"checks_per_epoch\": 1,\n",
    "    \"report_freq\": 200,\n",
    "    \"verbose\": true,\n",
    "    \"device\": \"cuda\",\n",
    "    \"buffer_size\": 10000,  // Sentence in memory\n",
    "    \"minimize_pad\": false,\n",
    "    \"shuffle\": true,\n",
    "    \"pretrain_embeddings\": false,\n",
    "    \"load_pretrained_embeddings\": \"\",\n",
    "    \"load_pretrained_encoder\": \"\",\n",
    "    \"freeze_embeddings\": false,\n",
    "    \"scorer\": \"general\"\n",
    "}\"\"\".split(\"\\n\") \n",
    "                             if not line.strip().startswith(\"//\") and line.strip()\n",
    "                            ]\n",
    "                           )\n",
    "                 )  # json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tasks\n",
    "with open(\"/home/thibault/dev/LASLA/mood-tense-voice-pft/test.tsv\") as f:\n",
    "    for line in f:\n",
    "        break\n",
    "data[\"tasks\"].extend([\n",
    "    {\"name\": task}\n",
    "    for task in line.split()\n",
    "    if task not in (\"lemma\", \"token\", \"Dis\", \"Entity\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 01: CNN vs RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "patience = copy.deepcopy(data)\n",
    "CNN = copy.deepcopy(data)\n",
    "RNN = copy.deepcopy(data)\n",
    "\n",
    "CNN[\"modelname\"] = \"cemb_CNN_-\"\n",
    "CNN[\"cemb_type\"] = \"cnn\"\n",
    "RNN[\"modelname\"] = \"cemb_RNN_-\"\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-CNN.json\", \"w\") as f:\n",
    "    json.dump(CNN, f)\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-RNN.json\", \"w\") as f:\n",
    "    json.dump(RNN, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 02: Different Patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "patience = copy.deepcopy(data)\n",
    "patience[\"patience\"] = 5\n",
    "\n",
    "CNN = copy.deepcopy(patience)\n",
    "RNN = copy.deepcopy(patience)\n",
    "\n",
    "CNN[\"modelname\"] = \"cemb_CNN_-patience_5_\"\n",
    "CNN[\"cemb_type\"] = \"cnn\"\n",
    "RNN[\"modelname\"] = \"cemb_RNN_-patience_5_\"\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-CNN-patience.json\", \"w\") as f:\n",
    "    json.dump(CNN, f)\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-RNN-patience.json\", \"w\") as f:\n",
    "    json.dump(RNN, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 03: Smaller Patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "patience = copy.deepcopy(data)\n",
    "patience[\"lr_patience\"] = 4\n",
    "patience[\"patience\"] = 7\n",
    "\n",
    "CNN = copy.deepcopy(patience)\n",
    "RNN = copy.deepcopy(patience)\n",
    "\n",
    "CNN[\"modelname\"] = \"cemb_CNN_-lrpatience_4;7_\"\n",
    "CNN[\"cemb_type\"] = \"cnn\"\n",
    "RNN[\"modelname\"] = \"cemb_RNN_-lrpatience_5;7_\"\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-CNN-lrpatience.json\", \"w\") as f:\n",
    "    json.dump(CNN, f)\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-RNN-lrpatience.json\", \"w\") as f:\n",
    "    json.dump(RNN, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 04: No Wemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "CNN = copy.deepcopy(CNN)\n",
    "RNN = copy.deepcopy(RNN)\n",
    "\n",
    "CNN[\"word_max_size\"] = 20000\n",
    "RNN[\"word_max_size\"] = 20000\n",
    "\n",
    "CNN[\"wemb_dim\"] = 0\n",
    "RNN[\"wemb_dim\"] = 0\n",
    "\n",
    "CNN[\"modelname\"] = \"cemb_CNN_-wemb_none_-lrpatience_4;7_\"\n",
    "CNN[\"cemb_type\"] = \"cnn\"\n",
    "RNN[\"modelname\"] = \"cemb_RNN_-wemb_none_-lrpatience_5;7_\"\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-CNN-nowemb.json\", \"w\") as f:\n",
    "    json.dump(CNN, f)\n",
    "\n",
    "with open(\"./configs/1.4.4.a-CNN_vs_RNN-RNN-nowemb.json\", \"w\") as f:\n",
    "    json.dump(RNN, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Wemb vs Wemb + Plus Grand Encodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'breakline_data': 'NONE',\n",
      " 'breakline_ref': 'pos',\n",
      " 'buffer_size': 10000,\n",
      " 'cell': 'GRU',\n",
      " 'cemb_dim': 300,\n",
      " 'cemb_layers': 2,\n",
      " 'cemb_type': 'rnn',\n",
      " 'char_bos': True,\n",
      " 'char_eos': True,\n",
      " 'char_max_size': 500,\n",
      " 'char_min_freq': 1,\n",
      " 'checks_per_epoch': 1,\n",
      " 'clip_norm': 5,\n",
      " 'custom_cemb_cell': False,\n",
      " 'decoder_layers': 3,\n",
      " 'dev_path': './mood-tense-voice-pft/dev.tsv',\n",
      " 'device': 'cuda',\n",
      " 'dropout': 0.25,\n",
      " 'epochs': 100,\n",
      " 'factor': 0.5,\n",
      " 'freeze_embeddings': False,\n",
      " 'header': True,\n",
      " 'hidden_size': 256,\n",
      " 'include_lm': True,\n",
      " 'input_path': './mood-tense-voice-pft/train.tsv',\n",
      " 'linear_layers': 1,\n",
      " 'lm_schedule': {'factor': 0.5, 'mode': 'min', 'patience': 2, 'weight': 0.2},\n",
      " 'lm_shared_softmax': True,\n",
      " 'load_pretrained_embeddings': '',\n",
      " 'load_pretrained_encoder': '',\n",
      " 'lr': 0.001,\n",
      " 'lr_patience': 4,\n",
      " 'max_sent_len': 35,\n",
      " 'max_sents': 1000000,\n",
      " 'merge_type': 'concat',\n",
      " 'min_weight': 0.2,\n",
      " 'minimize_pad': False,\n",
      " 'modelname': 'cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256',\n",
      " 'modelpath': './models/',\n",
      " 'num_layers': 1,\n",
      " 'optimizer': 'Adam',\n",
      " 'patience': 7,\n",
      " 'pretrain_embeddings': False,\n",
      " 'report_freq': 200,\n",
      " 'run_test': False,\n",
      " 'scorer': 'general',\n",
      " 'sep': '\\t',\n",
      " 'shuffle': True,\n",
      " 'task_defaults': {'context': 'sentence',\n",
      "                   'decoder': 'linear',\n",
      "                   'layer': -1,\n",
      "                   'level': 'token'},\n",
      " 'tasks': [{'context': 'sentence',\n",
      "            'decoder': 'attentional',\n",
      "            'layer': -1,\n",
      "            'level': 'char',\n",
      "            'name': 'lemma',\n",
      "            'settings': {'bos': True,\n",
      "                         'eos': True,\n",
      "                         'lower': True,\n",
      "                         'target': 'lemma'},\n",
      "            'target': True},\n",
      "           {'name': 'pos'},\n",
      "           {'name': 'Gend'},\n",
      "           {'name': 'Numb'},\n",
      "           {'name': 'Case'},\n",
      "           {'name': 'Deg'},\n",
      "           {'name': 'Mood_Tense_Voice'},\n",
      "           {'name': 'Person'}],\n",
      " 'test_path': './mood-tense-voice-pft/test.tsv',\n",
      " 'threshold': 0.0001,\n",
      " 'verbose': True,\n",
      " 'wemb_dim': 0,\n",
      " 'word_dropout': 0,\n",
      " 'word_max_size': 20000,\n",
      " 'word_min_freq': 1}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "Patience4_7 = copy.deepcopy(data)\n",
    "Patience4_7.update({\n",
    "    \"lr_patience\": 4,\n",
    "    \"patience\": 7,\n",
    "    \"word_max_size\": 20000,\n",
    "})\n",
    "\n",
    "RNN_NoWemb = copy.deepcopy(Patience4_7)\n",
    "RNN_NoWemb_L2 = copy.deepcopy(Patience4_7)\n",
    "RNN_NoWemb_L2_CEMB_400 = copy.deepcopy(Patience4_7)\n",
    "RNN_Wemb = copy.deepcopy(Patience4_7)\n",
    "RNN_Wemb_200 = copy.deepcopy(Patience4_7)\n",
    "\n",
    "RNN_NoWemb.update({\n",
    "    \"wemb_dim\": 0,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256\",\n",
    "    \"hidden_size\": 256,\n",
    "    #\"num_layers\": 2\n",
    "})\n",
    "import pprint\n",
    "pprint.pprint(RNN_NoWemb)\n",
    "RNN_NoWemb_L2.update({\n",
    "    \"wemb_dim\": 0,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2\",\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_layers\": 2\n",
    "})\n",
    "RNN_NoWemb_L2_CEMB_400.update({\n",
    "    \"wemb_dim\": 0,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_2-cemb_400\",\n",
    "    \"hidden_size\": 256,\n",
    "    \"cemb_dim\": 400\n",
    "})\n",
    "RNN_Wemb.update({\n",
    "    \"wemb_dim\": 100,\n",
    "    \"word_min_freq\": 5,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_100_min_5-lrpatience_4_7_-hidden-256\",\n",
    "    \"hidden_size\": 256,\n",
    "    #\"num_layers\": 2\n",
    "})\n",
    "RNN_Wemb_200.update({\n",
    "    \"wemb_dim\": 200,\n",
    "    \"word_min_freq\": 5,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_200_min_5_-lrpatience_4_7_-hidden-256\",\n",
    "    \"hidden_size\": 256,\n",
    "    #\"num_layers\": 2\n",
    "})\n",
    "\n",
    "with open(\"./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256.json\", \"w\") as f:\n",
    "    json.dump(RNN_NoWemb, f)\n",
    "\n",
    "with open(\"./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-layers_2.json\", \"w\") as f:\n",
    "    json.dump(RNN_NoWemb_L2, f)\n",
    "    \n",
    "with open(\"./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-cemb_400.json\", \"w\") as f:\n",
    "    json.dump(RNN_NoWemb_L2_CEMB_400, f)\n",
    "    \n",
    "with open(\"./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb-hidden_256.json\", \"w\") as f:\n",
    "    json.dump(RNN_Wemb, f)\n",
    "    \n",
    "with open(\"./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-wemb_200-hidden_256.json\", \"w\") as f:\n",
    "    json.dump(RNN_Wemb_200, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_NoWemb_Cemb500 = copy.deepcopy(RNN_NoWemb_L2_CEMB_400)\n",
    "RNN_NoWemb_Cemb400_Hid384 = copy.deepcopy(RNN_NoWemb_L2_CEMB_400)\n",
    "RNN_NoWemb_Cemb500_Hid384 = copy.deepcopy(RNN_NoWemb_L2_CEMB_400)\n",
    "RNN_NoWemb_RealL2_CEMB_400 = copy.deepcopy(RNN_NoWemb_L2_CEMB_400)\n",
    "RNN_NoWemb_RealL2_CEMB_400_Hid384 = copy.deepcopy(RNN_NoWemb_L2_CEMB_400)\n",
    "#with open(\"./configs/1.4.4.a-RNN-Wemb_vs_no_wemb-nowemb-hidden_256-cemb_400.json\", \"w\") as f:\n",
    "#    json.dump(RNN_NoWemb_L2_CEMB_400, f)\n",
    "\n",
    "RNN_NoWemb_RealL2_CEMB_400.update({\n",
    "    \"wemb_dim\": 0,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-real-layers_2-cemb_400\",\n",
    "    \"hidden_size\": 256,\n",
    "    \"cemb_dim\": 400,\n",
    "    \"num_layers\": 2\n",
    "})\n",
    "\n",
    "RNN_NoWemb_RealL2_CEMB_400_Hid384.update({\n",
    "    \"wemb_dim\": 0,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-real-layers_2-cemb_400\",\n",
    "    \"hidden_size\": 384,\n",
    "    \"cemb_dim\": 400,\n",
    "    \"num_layers\": 2\n",
    "})\n",
    "\n",
    "RNN_NoWemb_Cemb500.update({\n",
    "    \"wemb_dim\": 0,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-256-layers_1-cemb_500\",\n",
    "    \"hidden_size\": 256,\n",
    "    \"cemb_dim\": 500\n",
    "})\n",
    "\n",
    "RNN_NoWemb_Cemb400_Hid384.update({\n",
    "    \"wemb_dim\": 0,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_400\",\n",
    "    \"hidden_size\": 384,\n",
    "    \"cemb_dim\": 400\n",
    "})\n",
    "\n",
    "RNN_NoWemb_Cemb500_Hid384.update({\n",
    "    \"wemb_dim\": 0,\n",
    "    \"modelname\": \"cemb_RNN_-wemb_none_-lrpatience_4_7_-hidden-384-layers_1-cemb_500\",\n",
    "    \"hidden_size\": 384,\n",
    "    \"cemb_dim\": 500\n",
    "})\n",
    "\n",
    "configs = [\n",
    "    RNN_NoWemb_Cemb500, RNN_NoWemb_Cemb400_Hid384, RNN_NoWemb_Cemb500_Hid384, \n",
    "    RNN_NoWemb_RealL2_CEMB_400, RNN_NoWemb_RealL2_CEMB_400_Hid384\n",
    "]\n",
    "\n",
    "for file in configs:\n",
    "    with open(\"./configs/1.4.4.a-RNN-\"+file[\"modelname\"]+\".json\", \"w\") as f:\n",
    "        json.dump(file, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
