{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, emb_size=100, authors=2, maxwords=50):\n",
    "        self.embs = nn.Embedding(emb_size)\n",
    "        self.reduce = nn.Linear(emb_size, 1)\n",
    "        self.linear = nn.Linear(maxwords, authors)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # (batchsize, 50 words)\n",
    "        encoded = self.embs(batch)\n",
    "        # (batchsize, 50 words, 100 embeddings)\n",
    "        reduced = self.reduce(encoded)\n",
    "        # (batchsize, 50 words, 1 score)\n",
    "        reduced = reduced.unsqueeze(-1)\n",
    "        # (batchsize, 50 words)\n",
    "        classified = self.linear(reduced)\n",
    "        return classified\n",
    "    \n",
    "    def predict(self, batch):\n",
    "        return nn.Sigmoid(self.forward())\n",
    "    \n",
    "\n",
    "class Vocabulary(object):\n",
    "    def __init__(self):\n",
    "        self.itw = {0: \"<UNK>\", 1: \"<PAD>\"}\n",
    "        self.wti = {\"<UNK>\": 0, \"<PAD>\": 1}\n",
    "        self.maxsize = 50\n",
    "        self.unk = self.wti[\"<UNK>\"]\n",
    "    \n",
    "    @property\n",
    "    def count(self):\n",
    "        return len(self.itw)\n",
    "    \n",
    "    def unique_transcode(self, word, learn=True):\n",
    "        i = self.wti.get(word)\n",
    "        if not i:  # i = None\n",
    "            if not learn:\n",
    "                return self.unk\n",
    "            i = self.wti[word] = self.count()\n",
    "            self.itw[i] = word\n",
    "        return i\n",
    "    \n",
    "    def transcode(self, sentence):\n",
    "        return [self.unique_transcode(word) for word in sentence] + [self.pad]*(50-len(sentence)) # Pad\n",
    "\n",
    "    \n",
    "class Reader(object):\n",
    "    def __init__(self, files: Dict[str, int]):\n",
    "        self.files: Dict[str, int] = files  # Filepath, classe\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
