{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forbidden-feature",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "seventh-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import List, Dict\n",
    "from pandas import read_csv\n",
    "import lxml.etree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a4cea",
   "metadata": {},
   "source": [
    "# General setup (constants et al.)\n",
    "\n",
    "## Steps to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33028b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = True # Generate WEMBS training files\n",
    "GENSIM = True # Train Gensim models\n",
    "AEMB = False # Train Attentional WEMBS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-product",
   "metadata": {},
   "source": [
    "## Retrieve the datation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATATION = read_csv(\"../../data/raw/datation.tsv\", dialect=\"excel-tab\").fillna(\"\")\n",
    "DATATION = DATATION[DATATION[\"Ignore\"] == \"\"]\n",
    "TEXT_SPLITS = {\n",
    "    row[\"URN\"]: row[\"Citation level\"]\n",
    "    for _, row in DATATION.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-somalia",
   "metadata": {},
   "source": [
    "## Prepare the parsing of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "welsh-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_msd(attrib):\n",
    "    attrib = dict([tuple(sub.split(\"=\")) for sub in attrib.split(\"|\") if \"=\" in sub])\n",
    "    return {\n",
    "        morph_key: attrib.get(morph_key, \"_\")\n",
    "        for morph_key in (\"Case\", \"Numb\", \"Gend\", \"Mood\", \"Tense\", \"Voice\", \"Person\", \"Deg\")\n",
    "    }\n",
    "\n",
    "def get_chunks(\n",
    "    urn: str,\n",
    "    template=\"/home/thibault/dev/latin-lemmatized-texts/lemmatized/xml/{file}.xml\") -> List[str]:\n",
    "    \n",
    "    fp = template.format(file=urn)\n",
    "    if not os.path.isfile(fp):\n",
    "        return []\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    xml = ET.parse(fp)\n",
    "    last_n = None\n",
    "    for w in xml.xpath(\"//tei:w\", namespaces={\"tei\": \"http://www.tei-c.org/ns/1.0\"}):\n",
    "        n = w.attrib[\"n\"].split(\".\")[:TEXT_SPLITS[urn]]\n",
    "        \n",
    "        # If the last level is not the same, we create a new \"chunk\"\n",
    "        if last_n != n: \n",
    "            data.append([])\n",
    "            last_n = n\n",
    "            \n",
    "        if w.text[0] == \"{\":\n",
    "            continue\n",
    "        try:\n",
    "            data[-1].append({\n",
    "                \"token\": w.text,\n",
    "                \"lemma\": w.attrib[\"lemma\"],\n",
    "                \"pos\": w.attrib[\"pos\"],\n",
    "                **expand_msd(w.attrib[\"msd\"])\n",
    "            })\n",
    "        except ValueError:\n",
    "            print(expand_msd(w.attrib[\"msd\"]))\n",
    "            raise\n",
    "        \n",
    "        if w.text in {\".\", \"?\", \"!\", \"...\"}:\n",
    "            data.append([])\n",
    "    \n",
    "    return [d for d in data if d and len(d) > 1]\n",
    "\n",
    "def listdict_to_dictlist(listdict: List[Dict[str, str]]):\n",
    "    return {k: [dic[k] for dic in listdict] for k in listdict[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-sherman",
   "metadata": {},
   "source": [
    "# Create data for wembs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interpreted-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE:\n",
    "    task_files = {\n",
    "        key: open(f\"data/embs_data/{key}.txt\", \"w\")\n",
    "        for key in (\"Case\", \"Numb\", \"Gend\", \"Mood\", \"Tense\", \"Voice\", \"Person\", \"Deg\", \"token\", \"pos\", \"lemma\")\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    for file in list(TEXT_SPLITS.keys()):\n",
    "        chunks = get_chunks(file)\n",
    "        if chunks:\n",
    "            for chunk in chunks:\n",
    "                for task, content in listdict_to_dictlist(chunk).items():\n",
    "                    task_files[task].write(\" \".join(content)+\"\\n\")\n",
    "\n",
    "    for file in task_files.values():\n",
    "        file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92831a5",
   "metadata": {},
   "source": [
    "# Train Wembs with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fixed-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case\n",
      "Numb\n",
      "Gend\n",
      "Mood\n",
      "Tense\n",
      "Voice\n",
      "Person\n",
      "Deg\n",
      "token\n",
      "pos\n",
      "lemma\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in open(self.file):\n",
    "            yield line.split()\n",
    "\n",
    "            \n",
    "smalls = (\"Case\", \"Numb\", \"Gend\", \"Mood\", \"Tense\", \"Voice\", \"Person\", \"Deg\", \"pos\")\n",
    "large = (\"token\", \"lemma\")\n",
    "\n",
    "if GENSIM:\n",
    "    for task in task_files:\n",
    "        s = MySentences(f\"data/embs_data/{task}.txt\")\n",
    "        print(task)\n",
    "        if task in large:\n",
    "            model = Word2Vec(\n",
    "                sentences=s,\n",
    "                vector_size=200, window=10, min_count=1, workers=12\n",
    "            )\n",
    "            model = model.wv\n",
    "            model.save_word2vec_format(f\"data/embs_models/model.{task}.word2vec.kv\", write_header=False)\n",
    "            model = FastText(\n",
    "                sentences=s,\n",
    "                vector_size=200, window=10, min_count=1, workers=12\n",
    "            )\n",
    "            model = model.wv\n",
    "            model.save_word2vec_format(f\"data/embs_models/model.{task}.fasttext.kv\", write_header=False)\n",
    "        else:\n",
    "            model = Word2Vec(\n",
    "                sentences=s,\n",
    "                vector_size=10, window=10, min_count=1, workers=12\n",
    "            )\n",
    "            model = model.wv\n",
    "            model.save_word2vec_format(f\"data/embs_models/model.{task}.word2vec.kv\", write_header=False)\n",
    "            \n",
    "            model = Word2Vec(\n",
    "                sentences=s,\n",
    "                vector_size=3, window=15, min_count=1, workers=12\n",
    "            )\n",
    "            model = model.wv\n",
    "            model.save_word2vec_format(f\"data/embs_models/model.{task}.size3.w10.word2vec.kv\", write_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b57e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastTextKeyedVectors object at 0x7f0a25b19eb0>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2feef711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c89ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = KeyedVectors.load_word2vec_format(\"data/embs_models/model.lemma.fasttext.kv.header\")\n",
    "wv = KeyedVectors.load_word2vec_format(\"data/embs_models/model.lemma.word2vec.kv.header\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b18683e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lasciuus', 0.9449629187583923),\n",
       " ('lasciuibundus', 0.9286326169967651),\n",
       " ('lasciuiosus', 0.9245330691337585),\n",
       " ('lasciue', 0.914734959602356),\n",
       " ('lasciuio', 0.9087250828742981),\n",
       " ('nesciuus', 0.9015768766403198),\n",
       " ('uaciuus', 0.899739146232605),\n",
       " ('nociuus', 0.8996517658233643),\n",
       " ('luxuus', 0.8978460431098938),\n",
       " ('mollitiuus', 0.897210419178009),\n",
       " ('miuus', 0.8940095901489258),\n",
       " ('iuus', 0.8930966258049011),\n",
       " ('puxus', 0.891620397567749),\n",
       " ('lasciuia', 0.8905083537101746),\n",
       " ('lixiuus', 0.8902315497398376),\n",
       " ('luxus', 0.8876140713691711),\n",
       " ('landus', 0.8870022296905518),\n",
       " ('lasciuis', 0.8867684602737427),\n",
       " ('seriuus', 0.8865979909896851),\n",
       " ('asiuus', 0.8855615854263306)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.most_similar_cosmul(positive=[\"lasciuus\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b0ceef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lasciuio', 0.869053065776825),\n",
       " ('procax', 0.8673139810562134),\n",
       " ('libidinosus', 0.8551190495491028),\n",
       " ('lusus', 0.8514569401741028),\n",
       " ('blandus', 0.8478466868400574),\n",
       " ('garrulus', 0.8348168730735779),\n",
       " ('proteruus', 0.8346595168113708),\n",
       " ('salto', 0.8332166075706482),\n",
       " ('obscenus', 0.8296343684196472),\n",
       " ('petulans', 0.8249545693397522)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar_cosmul(positive=[\"lasciuus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a8fb3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = KeyedVectors.load_word2vec_format(\"/home/thibault/dev/attention-word-embedding/models/vectors200-10.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "284d37b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carmen1', 0.9400041103363037),\n",
       " ('Hispala', 0.9341803193092346),\n",
       " ('Astronus', 0.9333240985870361),\n",
       " ('Pacatianus', 0.9331989884376526),\n",
       " ('Insigne', 0.9320818781852722),\n",
       " ('Aegeus', 0.931224524974823),\n",
       " ('Rami', 0.9310905337333679),\n",
       " ('Bomin', 0.9305999279022217),\n",
       " ('hypodorius', 0.930131733417511),\n",
       " ('Clitiphus', 0.9299523234367371)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.most_similar_cosmul(positive=[\"lasciuus\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "638.767px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
